---
title: "2-5. 가설 검정 - 모분산, 정규성"
output: html_notebook
---

# 2-5-1 가설 검정 - 모분산

## 1. 단일 모집단 분산 검정

모분산($\sigma^2$)에 대한 검정입니다.

$H_0: \sigma^2 = \sigma^2_0$

$H_1:$

| 대립 가설                        | 검정 종류            |
|----------------------------------|----------------------|
| $$H_1: \sigma^2 < \sigma^2_0$$   | 좌측 꼬리(left)      |
| $$H_1: \sigma^2 > \sigma^2_0$$   | 우측 꼬리(right)     |
| $$H_1: \sigma^2 \ne \sigma^2_0$$ | 양쪽 꼬리(two-sided) |

모분산과 표본분산이 아래와 같은 성질이 있음을 이용합니다.

$(n-1)\frac{S^2}{\sigma^2} \sim \chi^2_{n-1}$, $n$은 표본수입니다.

**가정**

모집단은 정규 분포를 따릅니다.

표본은 서로 독립입니다.

$H_0: \frac{\sigma^2}{\sigma^2_0} = 1$

| 대립 가설                                  | 검정 종류            |
|--------------------------------------------|----------------------|
| $$H_1: \frac{\sigma^2}{\sigma^2_0} < 1$$   | 좌측 꼬리(left)      |
| $$H_1: \frac{\sigma^2}{\sigma^2_0} > 1$$   | 우측 꼬리(right)     |
| $$H_1: \frac{\sigma^2}{\sigma^2_0} \ne 1$$ | 양쪽 꼬리(two-sided) |

```         
※ 카이제곱분포는 비대칭 분포입니다.
   따라서 양측 검정할 때에 pvalue는 어림수(좌측과 우측 확률 중 작은(0.5 이하)×2)가 됩니다.
```

**증거의 확률 분포 및 통계량**

$H_0$ 가 맞다면,

> $\frac{\sigma^2}{\sigma^2_0} = 1$

확률 분포와 검정 통계량

> $X^2=(n-1)\frac{S^2}{\sigma_0^2} \sim \chi^2(n-1)$

**[Ex.1]**

::: {style="border: 1px solid #ddd; padding: 12px; margin-top: 10px"}
레이저를 이용한 거리 측정기를 개발 중에 있습니다.

기존에 거리 측정기의 품질 합격 기준은 100m 거리를 재었을 때,

유의 수준 5%로 거리의 표준편차가 0.25m 이내여야 통과가 됩니다.

모의로 100m에서 거리를 측정 했을 때의 실험 결과가 아래와 같습니다.

100m 지점에서 측정된 거리는 정규 분포를 따른 다고 가정합니다. 이 때, 통과 여부를 판단해 봅니다.

```         
99.674, 100.299, 100.085, 99.548, 99.826, 100.495, 99.272, 99.871, 100.380, 99.740, 
99.796, 99.972, 100.447, 99.808, 99.867, 99.870, 100.662, 100.656, 100.301, 100.116, 
100.221, 100.447, 99.719, 100.353, 99.624, 99.809, 100.272, 99.571, 99.958, 99.741
```
:::

$H_0: \sigma = 0.25$

$H_1: \sigma < 0.25$

$X^2=(n-1)\frac{S^2}{0.25^2} \sim \chi^2(n-1)$

**좌측 검정** 입니다.

```{r}
library(stats)

# 데이터 설정
X <- c(99.674, 100.299, 100.085, 99.548, 99.826, 100.495, 99.272, 99.871, 100.380, 99.740, 
       99.796, 99.972, 100.447, 99.808, 99.867, 99.870, 100.662, 100.656, 100.301, 100.116, 
       100.221, 100.447, 99.719, 100.353, 99.624, 99.809, 100.272, 99.571, 99.958, 99.741)

# 표본 분산 계산
S_sq <- var(X)
n <- length(X)

# 카이제곱 검정통계량 계산
Chi2 <- (n - 1) * S_sq / (0.25 ^ 2)

# p-value 계산
pvalue <- pchisq(Chi2, df = n - 1)

# 결과 출력
cat("검정통계량(Chi2):", Chi2, ", pvalue:", pvalue, "\n")
```

```{r}
# 표본 분산 계산
library(ggplot2)

# 그래프 그리기
x_values <- seq(1, 110, length.out = 100)
y_values <- dchisq(x_values, df = n - 1)

df <- data.frame(x = x_values, y = y_values)
chi2_df <- data.frame(x = Chi2, y = 0.01, label = sprintf("%.2f", Chi2))

ggplot(df, aes(x = x, y = y)) +
  geom_line() +
  geom_vline(xintercept = Chi2, color = 'red', linetype = 'dashed') +
  geom_text(data = chi2_df, aes(x = x, y = y, label = label), vjust = -1) +
  geom_area(data = subset(df, x <= Chi2), aes(y = y), fill = 'orange', alpha = 0.5) +
  labs(title = 'Chi-Square Distribution', x = 'Chi-Square Value', y = 'Density') +
  theme_minimal()
```

## 두 개의 모집단의 분산 검정

두 개의 모집단의 분산($\sigma^2_1$), 분산($\sigma^2_2$)에 대한 검정입니다.

$H_0: \sigma^2_1 = \sigma^2_2$

$H_1:$

| 대립 가설                          | 검정 종류            |
|------------------------------------|----------------------|
| $$H_1: \sigma^2_1 < \sigma^2_2$$   | 좌측 꼬리(left)      |
| $$H_1: \sigma^2_1 > \sigma^2_2$$   | 우측 꼬리(right)     |
| $$H_1: \sigma^2_1 \ne \sigma^2_2$$ | 양쪽 꼬리(two-sided) |

### F 검정 (F-test)

**가정**

두 개의 모집단은 정규 분포를 따릅니다.

각 표본들은 서로 독립입니다.

$H_0: \frac{\sigma^2_1}{\sigma^2_2} = 1$

$H_1:$

| 대립 가설                                  | 검정 종류            |
|--------------------------------------------|----------------------|
| $$H_1: \frac{\sigma^2_1}{\sigma^2_2} < 1$$ | 좌측 꼬리(left)      |
| $$H_1: \frac{\sigma^2_1}{\sigma^2_2} > 1$$ | 우측 꼬리(right)     |
| $$H_1: \sigma^2_1 \ne \sigma^2_2$$         | 양쪽 꼬리(two-sided) |

```         
※ F분포는 비대칭 분포입니다.
   따라서 양측 검정할 때에 pvalue는 어림수(좌측과 우측 확률 중 작은(0.5 이하)×2)가 됩니다.
```

**증거의 확률 분포 및 통계량**

$H_0$ 가 맞다면,

> $\frac{\sigma^2_1}{\sigma^2_2} = 1$가 됩니다.

확률 분포와 검정 통계량

> $F=\frac{S_1^2}{S_2^2} \sim F(n_1-1, n_2-1)$, n: 표본수

**유도 과정**

$(n_1-1)\frac{S_1^2}{\sigma_1^2} \sim \chi^2(n_1-1)$

$(n_2-1)\frac{S_2^2}{\sigma_2^2} \sim \chi^2(n_2-1)$

$\frac{\frac{S_1^2}{\sigma_1^2}}{\frac{S_2^2}{\sigma_2^2}} \sim \frac{\chi^2(n_1-1)/(n_1-1)}{\chi^2(n_2-1)/(n_2-1)}$

$\frac{S_1^2}{S_2^2} \sim F(n_1-1, n_2-1)$

**[Ex.2]**

::: {style="border: 1px solid #ddd; padding: 12px; margin-top: 10px"}
신형 거리 계산기를 개발 중에 있습니다.

기존에 거리 계산기 보다 거리를 재었을 때보다 분산이 낮게 만드는 것을 목표로 하고 있습니다.

신형 거리 계산기의 개발의 성공 기준은 100m 거리를 재었을 때를 기준으로 합니다.

100m에서 거리를 측정 했을 때의 실험 결과가 아래와 같습니다.

유의 수준을 5%로 했을 때 기존 거리 계산기 보다 분산이 낮다고 판단할 수 있는지 확인합니다.

기존 거리 계산기 기록

```         
99.674, 100.299, 100.085, 99.548, 99.826, 100.495, 99.272, 99.871, 100.380, 99.740, 
99.796, 99.972, 100.447, 99.808, 99.867, 99.870, 100.662, 100.656, 100.301, 100.116, 
100.221, 100.447, 99.719, 100.353, 99.624, 99.809, 100.272, 99.571, 99.958, 99.741
```

신형 거리 계산기 기록

```         
99.696, 100.279, 100.079, 99.578, 99.838, 100.462, 99.321, 99.880, 100.354, 99.757, 
99.810, 99.973, 100.418, 99.821, 99.876, 99.878, 100.618, 100.612, 100.281, 100.108, 
100.206, 100.417, 99.738, 100.329, 99.649, 99.821, 100.254, 99.600, 99.961, 99.759, 
99.928, 99.216, 99.504, 99.804, 100.260
```
:::

$H_0: \frac{\sigma^2_1}{\sigma^2_2} = 1$

$H_1: \frac{\sigma^2_1}{\sigma^2_2} > 1$

$F=\frac{S_1^2}{S_2^2} \sim F(n_1-1, n_2-1)$

**우측 검정** 입니다.

```{r}
# 데이터 설정
X1 <- c(99.674, 100.299, 100.085, 99.548, 99.826, 100.495, 99.272, 99.871, 100.380, 99.740, 
        99.796, 99.972, 100.447, 99.808, 99.867, 99.870, 100.662, 100.656, 100.301, 100.116, 
        100.221, 100.447, 99.719, 100.353, 99.624, 99.809, 100.272, 99.571, 99.958, 99.741)

X2 <- c(99.696, 100.279, 100.079, 99.578, 99.838, 100.462, 99.321, 99.880, 100.354, 99.757, 
        99.810, 99.973, 100.418, 99.821, 99.876, 99.878, 100.618, 100.612, 100.281, 100.108, 
        100.206, 100.417, 99.738, 100.329, 99.649, 99.821, 100.254, 99.600, 99.961, 99.759, 
        99.928, 99.216, 99.504, 99.804, 100.260)

# 표본 분산 계산
S1_sq <- var(X1)
S2_sq <- var(X2)

n1 <- length(X1)
n2 <- length(X2)

# F 검정통계량 계산
F <- S1_sq / S2_sq

# p-value 계산
pvalue <- pf(F, df1 = n1 - 1, df2 = n2 - 1, lower.tail = FALSE)

# 결과 출력
cat("검정통계량(F):", F, ", pvalue:", pvalue, "\n")
```

```{r}
# 그래프 그리기
x_values <- seq(0, 3, length.out = 100)
y_values <- df(x_values, df1 = n1 - 1, df2 = n2 - 1)

df <- data.frame(x = x_values, y = y_values)
f_df <- data.frame(x = F, y = 0.01, label = sprintf("%.2f", F))

ggplot(df, aes(x = x, y = y)) +
  geom_line() +
  geom_vline(xintercept = F, color = 'red', linetype = 'dashed') +
  geom_text(data = f_df, aes(x = x, y = y, label = label), vjust = -1) +
  geom_area(data = subset(df, x >= F), aes(y = y), fill = 'orange', alpha = 0.5) +
  labs(title = 'F Distribution', x = 'F Value', y = 'Density') +
  theme_minimal()
```

## 2. 다수의 모집단의 등분산 검정

$H_0: \sigma^2_0 = \sigma^2_1 = ... = \sigma^2_{k}$

$H_1$: 모집단 간 분산에 차이가 존재합니다.

### Bartlett 검정

**가정**

모집단들은 정규분포를 따릅니다.

**증거의 확률 분포 및 통계량**

$H_0$가 맞다면,

아래 B는 근사적으로 카이제곱분포를 따릅니다.

우측 검정입니다.

$B = \frac{(N - k) \ln(S_p^2) - \sum_{i=1}^k(n_i - 1)ln(S_i^2)}{1 + \frac{1}{3(k-1)} \left(\sum_{i=1}^{k}\left(\frac{1}{n_i-1}\right) - \frac{1}{N-k}\right)} \sim \chi^2(k - 1)$

-   k: 모집단의 수
-   N: 전체표본의 수

**[Ex.3]**

::: {style="border: 1px solid #ddd; padding: 12px; margin-top: 10px"}
다음 거리 계산기 모집단이 등분산인지 조사해보세요. 세 모집단은 모두 정규 분포를 따릅니다.

기존 거리 계산기 기록

```         
99.674, 100.299, 100.085, 99.548, 99.826, 100.495, 99.272, 99.871, 100.380, 99.740, 
99.796, 99.972, 100.447, 99.808, 99.867, 99.870, 100.662, 100.656, 100.301, 100.116, 
100.221, 100.447, 99.719, 100.353, 99.624, 99.809, 100.272, 99.571, 99.958, 99.741
```

신형 거리 계산기 기록

```         
99.696, 100.279, 100.079, 99.578, 99.838, 100.462, 99.321, 99.880, 100.354, 99.757, 
99.810, 99.973, 100.418, 99.821, 99.876, 99.878, 100.618, 100.612, 100.281, 100.108, 
100.206, 100.417, 99.738, 100.329, 99.649, 99.821, 100.254, 99.600, 99.961, 99.759, 
99.928, 99.216, 99.504, 99.804, 100.260
```

경쟁사 거리 계산기 기록

```         
99.653, 100.319, 100.091, 99.518, 99.815, 100.528, 99.223, 99.863, 100.405, 99.723, 
99.783, 99.970, 100.477, 99.796, 99.858, 99.861, 100.706, 100.700, 100.321, 100.124, 
100.236, 100.477, 99.701, 100.376, 99.599
```
:::

```{r}
library(dplyr)

# 데이터 설정
s_A <- data.frame(m = c(99.674, 100.299, 100.085, 99.548, 99.826, 100.495, 99.272, 99.871, 100.380, 99.740, 
                        99.796, 99.972, 100.447, 99.808, 99.867, 99.870, 100.662, 100.656, 100.301, 100.116, 
                        100.221, 100.447, 99.719, 100.353, 99.624, 99.809, 100.272, 99.571, 99.958, 99.741))

s_B <- data.frame(m = c(99.696, 100.279, 100.079, 99.578, 99.838, 100.462, 99.321, 99.880, 100.354, 99.757, 
                        99.810, 99.973, 100.418, 99.821, 99.876, 99.878, 100.618, 100.612, 100.281, 100.108, 
                        100.206, 100.417, 99.738, 100.329, 99.649, 99.821, 100.254, 99.600, 99.961, 99.759, 
                        99.928, 99.216, 99.504, 99.804, 100.260))

s_C <- data.frame(m = c(99.653, 100.319, 100.091, 99.518, 99.815, 100.528, 99.223, 99.863, 100.405, 99.723, 
                        99.783, 99.970, 100.477, 99.796, 99.858, 99.861, 100.706, 100.700, 100.321, 100.124, 
                        100.236, 100.477, 99.701, 100.376, 99.599))

# 데이터프레임 결합
df_m <- bind_rows(
  s_A %>% mutate(model = 'A'),
  s_B %>% mutate(model = 'B'),
  s_C %>% mutate(model = 'C')
)

# 결과 출력
print(df_m)
```

$B = \frac{(N - k) \ln(S_p^2) - \sum_{i=1}^k(n_i - 1)ln(S_i^2)}{1 + \frac{1}{3(k-1)} \left(\sum_{i=1}^{k}\left(\frac{1}{n_i-1}\right) - \frac{1}{N-k}\right)} \sim \chi^2(k - 1)$

```{r}
# 그룹별로 분산과 개수 계산
df_sp <- df_m %>%
  group_by(model) %>%
  summarise(var = var(m), count = n())

# 결과 출력
print(df_sp)
```

```{r}
library(stats)

# Pooled Variance 계산
Sp_sq <- sum(df_sp$var * (df_sp$count - 1)) / sum(df_sp$count - 1)
k <- 3
n <- nrow(df_m)

# B의 분모와 분자 계산
B_num <- (n - k) * log(Sp_sq) - sum(log(df_sp$var) * (df_sp$count - 1))
B_denom <- 1 + 1 / (3 * (k - 1)) * (sum(1 / (df_sp$count - 1)) - 1 / (n - k))
B <- B_num / B_denom

# p-value 계산
pvalue <- pchisq(B, df = k - 1, lower.tail = FALSE)

# 결과 출력
cat("검정통계량(B):", B, ", pvalue:", pvalue, "\n")
```

```{r}
# Bartlett's test 수행
# 데이터 설정
s_A <- c(99.674, 100.299, 100.085, 99.548, 99.826, 100.495, 99.272, 99.871, 100.380, 99.740, 
         99.796, 99.972, 100.447, 99.808, 99.867, 99.870, 100.662, 100.656, 100.301, 100.116, 
         100.221, 100.447, 99.719, 100.353, 99.624, 99.809, 100.272, 99.571, 99.958, 99.741)

s_B <- c(99.696, 100.279, 100.079, 99.578, 99.838, 100.462, 99.321, 99.880, 100.354, 99.757, 
         99.810, 99.973, 100.418, 99.821, 99.876, 99.878, 100.618, 100.612, 100.281, 100.108, 
         100.206, 100.417, 99.738, 100.329, 99.649, 99.821, 100.254, 99.600, 99.961, 99.759, 
         99.928, 99.216, 99.504, 99.804, 100.260)

s_C <- c(99.653, 100.319, 100.091, 99.518, 99.815, 100.528, 99.223, 99.863, 100.405, 99.723, 
         99.783, 99.970, 100.477, 99.796, 99.858, 99.861, 100.706, 100.700, 100.321, 100.124, 
         100.236, 100.477, 99.701, 100.376, 99.599)

test_result <- bartlett.test(list(s_A, s_B, s_C))

# 결과 출력
test_result
```

# 2-5-2 정규성 검정

정규성 검정은 모집단이 정규 분포를 따르는 지를 표본을 통해 확인하는 방법입니다.

정규 분포를 따르는 정도를 비교하기 위해,

표본의 수가 클수록 표본의 평균은 정규 분포에 가까워지는 성질을 이용하여 데이터셋을 만듭니다.

$\lambda=3$인 포아송 분포를 따르는 표본수를 3개로 할 때와 30개로 할 때의 표본의 평균을 각각 100개씩 만듭니다.

```{r}
library(stats)

# lambda=3인 지수 분포에서 표본을 3개씩 뽑아 평균을 100개 만듭니다.
s_mean_3 <- replicate(100, mean(rexp(3, rate = 3)))

# lambda=3인 지수 분포에서 표본을 30개씩 뽑아 평균을 100개 만듭니다.
s_mean_30 <- replicate(100, mean(rexp(30, rate = 3)))
```

### Q-Q Plot

비교할 대상 확률 분포를 정규 분포로하여 Q-Q Plot을 출력하여 판단합니다.

Q-Q Plot의 모양이 직선에 가까울 수록 두 확률 변수의 분포가 비슷합니다.

**Q-Q Plot 그리기**

::: {style="border: 0px solid #ddd; padding: 12px; margin-top: 10px"}
수열을 정렬합니다.

Y좌표: 수열

X좌표:

> 1.  수열의 값을 분위수(0\~1사이)로 변환하고 (순위 / 표본수)
>
> 2.  백분위수로 변환된 값을 정규 분포의 확률 변수로 변환합니다.(norm.ppf)

산포도 그래프로 출력합니다.

-   X와 Y의 분포가 비슷할 수록 산포도 그래프의 출력 형태는 직선에 가깝게 됩니다.
:::

```{r}
# 분위를 구하기 위해 정렬합니다.
X <- sort(s_mean_3)
# 표본의 등분위(0~1사이)를 구합니다.
X_ppf <- seq(0, 99) / 100
# 정규 분포의 분위수
X_norm_ppf <- qnorm(X_ppf, mean = mean(X), sd = sd(X))

# 그래프 그리기
p1 <- ggplot(data.frame(X = X), aes(x = X)) +
  geom_density() +
  labs(title = "Density Plot of s_mean_3")

# 0분위와 1분위의 정규 분포의 확률 변수는 -∞과 ∞ 이므로 생략합니다.
p2 <- ggplot(data.frame(X_norm_ppf = X_norm_ppf[2:99], X = X[2:99]), aes(x = X_norm_ppf, y = X)) +
  geom_point() +
  labs(x = "Normal theoretical quantiles", y = "s_mean_3", title = "Q-Q Plot")

# 출력
print(p1)
print(p2)
```

```{r}
# 분위를 구하기 위해 정렬합니다.
X <- sort(s_mean_30)
# 표본의 등분위(0~1사이)를 구합니다.
X_ppf <- seq(0, 99) / 100
# 정규 분포의 분위수
X_norm_ppf <- qnorm(X_ppf, mean = mean(X), sd = sd(X))

# 그래프 그리기
p1 <- ggplot(data.frame(X = X), aes(x = X)) +
  geom_density() +
  labs(title = "Density Plot of s_mean_3")

# 0분위와 1분위의 정규 분포의 확률 변수는 -∞과 ∞ 이므로 생략합니다.
p2 <- ggplot(data.frame(X_norm_ppf = X_norm_ppf[2:99], X = X[2:99]), aes(x = X_norm_ppf, y = X)) +
  geom_point() +
  labs(x = "Normal theoretical quantiles", y = "s_mean_3", title = "Q-Q Plot")

# 출력
print(p1)
print(p2)
```

$H_0$: 모집단은 정규 분포를 따릅니다.

$H_1$: 모집단은 정규 분포를 따르지 않습니다.

### Shapiro-Wilks

**증거의 확률 분포 및 통계량**

$W = \frac{\left(\sum_{i=1}^{n} a_i x_{(i)}\right)^2}{\sum_{i=1}^{n} (x_i - \bar{x})^2}$

$x_{(i)}$: i번째로 큰수

$(a_1, ..., a_n) = \frac{m^TV^{-1}}{C}$

$C=||V^{-1}m||=\left(m^TV^{-1}V^{-1}m\right)$

n: 표본수

**m과 V의 정체**

표본의 통계량(평균, 분산)으로 정규 분포에서 n개씩 표본 수집을 여러 번 수행합니다.

각 수행에서 순위가 1, ... , n까지 수들의 평균이 **m** 입니다.

그리고 순위가 1, ..., n까지의 수들 간에 공분산 행렬이 **V**입니다.

**W**가 따르는 분포는 정의할 수 없습니다. 단지 **W**가 클수록 정규 분포에 가깝습니다.

pvalue와 임계치는 Monte Carlo Simulation을 통해 구해집니다.

중소 규모(보통 2000개 이하)의 표본에 적합합니다.

```{r}

# Shapiro-Wilk 테스트 수행
shapiro_test_3 <- shapiro.test(s_mean_3)
shapiro_test_30 <- shapiro.test(s_mean_30)

# 결과 출력
print(shapiro_test_3)
print(shapiro_test_30)
```

### Kolmogorov-Smirnof

**증거의 확률 분포 및 통계량**

이론적 누적분포함수와 표본의 누적분포를 비교합니다.

$D_n = sup_x|F_n(x) - F(x)|$

$F_n(x) = \frac{1}{n}\sum_{i=1}^{n}{1_{(-\inf, x]}(X_i)}$, $1_{(-\inf, x]}(X_i)$:는 $X_i$보다 x가 작거나 같으면 1 아니면 0

즉, $F_n(x)$는 표본에서 x보다 작거나 같은 수의 수를 의미합니다.

$D_n$가 클수록 정규 분포와 거리가 먼 것을 의미합니다.

```{r}
# Kolmogorov-Smirnov 테스트 수행
ks_test_3 <- ks.test(s_mean_3, "pnorm", mean = mean(s_mean_3), sd = sd(s_mean_3))
ks_test_30 <- ks.test(s_mean_30, "pnorm", mean = mean(s_mean_30), sd = sd(s_mean_30))

# 결과 출력
print(ks_test_3)
print(ks_test_30)
```

### Jaque-Bera

왜도(skewness)와 첨도(kurtosis)를 이용하여 정규성 검정을 합니다.

검정 통계량은 카이제곱분포에 표본수가 커짐에 따라 점진적으로 수렴합니다.

따라서, 표본수가 적으면(2000개 미만) 정확도가 떨어 집니다.

**증거의 확률 분포 및 통계량**

$JB = \frac{n}{6} \left(\frac{S^2}{6} + \frac{(K-3)^2}{24}\right)$

S: 첨도, K: 왜도

$S = \frac{\sum_{i=1}^{n} (x_i - \bar{x})^3}{n \cdot s^3}$

$K = \frac{\sum_{i=1}^{n} (x_i - \bar{x})^4}{n \cdot s^4}$

```{r}
library(tseries)

# Jarque-Bera 테스트 수행
jb_test_3 <- jarque.bera.test(s_mean_3)
jb_test_30 <- jarque.bera.test(s_mean_30)

# 결과 출력
print(jb_test_3)
print(jb_test_30)
```
