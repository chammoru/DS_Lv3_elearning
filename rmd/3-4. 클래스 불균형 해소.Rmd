---
title: "3-4. 클래스 불균형 해소"
output: html_notebook
---

# 3-4. 클래스 불균형 해소(Class Imbalance)


- 클래스 불균형 문제는 클래스의 출현 빈도의 차이가 심한 상태를 의미합니다.


- 클래스의 불균형으로 인한 성능 저하를 완화하기 위한 방법들을 알아봅니다.


- f1 점수(f1 score), 매크로 재현율(Macro recall)과 같이 소수의 클래스의 분류 정확도를 올리면 성능 향상을 기대할 수 있습니다. 클래스 불균형 해소를 통해 성능의 개선 효과를 기대할 수 있습니다.

> $\text{f1 점수(f1 score)} = 2 × \frac{Recall × Precision }{Recall + Precision}$
>
> $\text{매크로 재현율(Macro recall)} = \frac{1}{c}\sum_{i=1}^c \text{Recall}_i$, $\text{Recall}_i$: i 클래스를 양성으로 했을 때의 재현율(Recall)


## 0. 데이터셋 소개

### SMS Spam dataset

[Spam](https://archive.ics.uci.edu/dataset/228/sms+spam+collection):SMS 텍스트로 메세지와 Spam 여부를 나타낸 데이터셋입니다.

|Name|Type|Description|
|----|---|---------|
|target|binary|ham or spam|
|message|text|SMS message|

텍스트를 입력으로 분류를 연습하기 위한 데이터셋입니다.


```{r}
library(readr)

df_sms <- read_tsv("../data/SMSSpamCollection.tsv")
df_sms
```

df_sms에서 message를 모델의 입력으로 사용하기 위해 단어의 최소 출현 빈도를 5로 하여 Bag of Model로 만들고, 

TFIDF을 적용한다음, Latenst Semantic Analysis 모델을 이용하여 4개의 차원으로 축소합니다.

```{r}
library(dplyr)
library(tidyr)
library(tidytext)
library(tm)
library(SnowballC)
library(caret)
library(text2vec)
library(Matrix)
library(slam)


# 데이터 전처리
data_clean <- df_sms %>%
  mutate(message = tolower(message)) %>%
  unnest_tokens(word, message) %>%
  anti_join(stop_words) %>%
  count(target, word, sort = TRUE) %>%
  ungroup()

# 빈도수가 5 이상인 단어만 사용
word_freq <- data_clean %>%
  group_by(word) %>%
  summarize(total = sum(n)) %>%
  filter(total >= 5)

data_filtered <- data_clean %>%
  inner_join(word_freq, by = "word")

# Bag of Words
corpus <- Corpus(VectorSource(df_sms$message))
dtm <- DocumentTermMatrix(corpus, control = list(dictionary = word_freq$word, wordLengths = c(1, Inf)))

# TF-IDF
dtm_tfidf <- DocumentTermMatrix(corpus,
                                control = list(dictionary = word_freq$word, weighting = weightTfIdf, wordLengths = c(1, Inf)))


# LSA 모델 (Latent Semantic Analysis)
dtm_tfidf_matrix <- as.matrix(dtm_tfidf)
lsa_model <- text2vec::LatentSemanticAnalysis$new(n_topics = 4)
doc_topic_matrix <- lsa_model$fit_transform(dtm_tfidf_matrix)

# 데이터셋 준비
df_sms_final <-  cbind(df_sms , doc_topic_matrix) %>% select(-message) %>%
  rename(X1 = 2, X2 = 3, X3 = 4, X4 = 5) %>% mutate(target=factor(target))

df_sms_final
```

## 1. Over sampling

- 빈도가 상대적으로 적은 클래스 데이터를 더 생성하여 불균형을 해소하는 방법입니다.

### Random Over Sampling

샘플할 클래스와 동일한 클래스인 데이터 중에서 임의로 뽑아내는 샘플링 방법입니다.


**[Ex.1]** 

클래스수가 2개인 클래스 불균형 지닌 데이터셋을 만들고,

samping_strategy 설정에 따라 추출된 데이터의 클래스의 개수를 확인하여 OverSampler의 동작을 확인합니다. 

```
[0.1, 0.5, 1.0]
```

```{r}
# 필요한 라이브러리 불러오기
library(mlbench)
library(dplyr)

# 데이터 생성
set.seed(123)
data <- mlbench.2dnormals(n = 5000, cl = 2, sd = 0.8)
df <- as.data.frame(data$x)
df$Class <- as.factor(data$classes)

# 클래스 분포 조정 (불균형 데이터)
class_weights <- c(0.01, 0.99)
sampled_idx <- c(
  sample(which(df$Class == 1), size = round(0.01 * nrow(df)), replace = TRUE),
  sample(which(df$Class == 2), size = round(0.99 * nrow(df)), replace = TRUE)
)
df <- df[sampled_idx, ]

# 클래스 0과 1로 변환
df$Class <- factor(ifelse(df$Class == 1, 0, 1))

# 결과 확인
table(df$Class)

# 시각화
library(ggplot2)
ggplot(df, aes(x = V1, y = V2, color = Class)) +
  geom_point() +
  labs(title = "Generated Classification Data",
       x = "Feature 1", y = "Feature 2") +
  theme_minimal()
```

```{r}
library(ROSE)
library(reshape2)

class_cnt <- list(table(df$Class) %>% as.data.frame() %>% mutate(strategy = 'Original'))

# 다양한 샘플링 전략 적용
for (i in c(0.1, 0.5, 1.0)) {
  print(i)
  df_ros <- ovun.sample(Class ~ ., data = df, method = "over", N = sum(df$Class == 1) + sum(df$Class == 1) * i, seed = 123)$data
  
  class_cnt <- append(
    class_cnt, list(table(df_ros$Class) %>% as.data.frame() %>% mutate(strategy = paste("Sampling strategy:", i)))
  )
}

# 결과 확인
class_cnt_df <- bind_rows(class_cnt) %>%
  rename(Class = Var1) %>%
  select(strategy, Class, Freq) %>%
  dcast(strategy ~ Class, value.var = "Freq")

class_cnt_df
```

**[Ex.2]** 

클래스수가 3개인 클래스 불균형 지닌 데이터셋을 만듭니다.

0번 클래스의 비율은 0.01, 1번 클래스의 비율은 0.97 그리고 2번 클래스의 비율은 0.02 이 되도록 하여 총 5000개의 

데이터를 만듭니다.

samping_strategy 설정에 따라 추출된 데이터의 클래스의 개수를 확인하여 OverSampler의 동작을 확인합니다. 


클래스의 수가 {0: 200, 2: 300} 되도록 Over sampling을 합니다. 


```{r}
# 데이터 생성
set.seed(123)
data <- mlbench::mlbench.2dnormals(n = 5000, cl = 3, sd = 0.8)
df <- as.data.frame(data$x)
df$Class <- as.factor(data$classes)

# 클래스 분포 조정 (불균형 데이터)
class_weights <- c(0.01, 0.97, 0.02)
sampled_idx <- c(
  sample(which(df$Class == 1), size = round(class_weights[1] * nrow(df)), replace = TRUE),
  sample(which(df$Class == 2), size = round(class_weights[2] * nrow(df)), replace = TRUE),
  sample(which(df$Class == 3), size = round(class_weights[3] * nrow(df)), replace = TRUE)
)
df <- df[sampled_idx, ]
```

```{r}
library(ROSE)
library(dplyr)
library(reshape2)

# 원본 클래스 분포 확인
class_cnt <- list(data.frame(table(df$Class)) %>% rename(Freq = Freq) %>% mutate(strategy = 'Original'))

# 특정 클래스 샘플링 전략 적용
# 클래스 0: 200개, 클래스 2: 300개로 오버샘플링
class0_oversampled <- df %>% filter(Class == 1) %>% sample_n(200, replace = TRUE)
class1_oversampled <- df %>% filter(Class == 3) %>% sample_n(300, replace = TRUE)
class2 <- df %>% filter(Class == 2)

# 오버샘플링 된 데이터 결합
df_os <- bind_rows(class0_oversampled, class1_oversampled, class2)

# 새로운 클래스 분포 추가
class_cnt <- append(
  class_cnt, list(data.frame(table(df_os$Class)) %>% rename(Freq = Freq) %>% mutate(strategy = 'Sampling strategy: {0: 200, 2: 300}'))
)

# 결과 확인 및 변환
class_cnt_df <- bind_rows(class_cnt) %>%
  rename(Class = Var1) %>%
  dcast(strategy ~ Class, value.var = "Freq")

# 결과 출력
print(class_cnt_df)
```

이후 클래스 불균형 처리 방법에서 예시를 들기 위한 데이터 처리 작업입니다.

df_sms_final 데이터셋의 타겟 변수인 target의 비율을 동일하게 하여,

80%는 학습데이터 df_train으로, 20%는 평가데이터 df_test로 나눕니다.

target가 'spam'인 경우가 양성(Positive)이고 0이 음성(Negative) 입니다.

```{r}
library(caret)
# 데이터 분할
set.seed(123)
trainIndex <- createDataPartition(df_sms_final$target, p = 0.8, list = FALSE, times = 1)
df_train <- df_sms_final[trainIndex, ]
df_test <- df_sms_final[-trainIndex, ]

# 데이터 분할 결과 확인
table(df_train$target)
table(df_test$target)
```

```{r}
library(nnet)  # for multinom function
X_cols <- setdiff(names(df_train), 'target')

# F1 스코어 함수
F1_Score <- function(pred, actual, positive) {
  cm <- confusionMatrix(pred, actual, mode = "prec_recall", positive = positive)
  f1 = cm[["byClass"]]["F1"][[1]]
  if (is.na(f1)) {
    f1 <- 0
  }
  return(f1)
}

eval_model <- function(clf, df_train, df_test,  ...) {
  # 모델 학습
  model <- clf(df_train[, X_cols], df_train$target, ...)
  # 예측 수행
  pred_train <- predict(model, df_train[, X_cols])
  pred_test <- predict(model, df_test[, X_cols])
  # 정확도 계산
  train_accuracy <- mean(pred_train == df_train$target)
  train_f1 <- F1_Score(pred_train, df_train$target, positive = "spam")
  
  test_accuracy <- mean(pred_test== df_test$target)
  test_f1 <- F1_Score(pred_test, df_test$target, positive = "spam")
  return (c(train_accuracy, train_f1, test_accuracy, test_f1))
}

# 로지스틱 회귀 모델 설정
logistic_reg <- function(X, y, ...) {
  multinom(y ~ ., data = data.frame(X, y), ...)
}

# 초기화
f1_train_ros <- c()
f1_test_ros <- c()
acc_train <- c()
acc_test <- c()

# 오버샘플링하지 않았을 경우의 성능 기록
result <- eval_model(logistic_reg, df_train, df_test, trace=FALSE)
acc_train <- c(acc_train, result[1])
f1_train_ros <- c(f1_train_ros, result[2])
acc_test <- c(acc_test, result[3])
f1_test_ros <- c(f1_test_ros, result[4])

# 제시한 오버샘플링 비율에 따른 성능 측정
postive_ratio <- c(0.2, 0.25, 0.3, 0.4, 0.5)
for (i in postive_ratio) {
  df_train_ros <- ovun.sample(target ~ ., data = df_train, method = "over", N = floor((1 + i) * nrow(df_train)))$data
  result <- eval_model(logistic_reg, df_train_ros, df_test, trace=FALSE)
  acc_train <- c(acc_train, result[1])
  f1_train_ros <- c(f1_train_ros, result[2])
  acc_test <- c(acc_test, result[3])
  f1_test_ros <- c(f1_test_ros, result[4])
}

postive_ratio <- c(sum(df_train$target == 'spam') / nrow(df_train), postive_ratio)

# 결과 시각화
results <- data.frame(
  Ratio = c(postive_ratio),
  F1_Train = f1_train_ros,
  F1_Test = f1_test_ros,
  Accuracy_Train = acc_train,
  Accuracy_Test = acc_test
)
```

```{r}
ggplot(results, aes(x = Ratio)) +
  geom_line(aes(y = F1_Train, color = 'F1 Train')) +
  geom_line(aes(y = F1_Test, color = 'F1 Test')) +
  geom_line(aes(y = Accuracy_Train, color = 'Accuracy Train')) +
  geom_line(aes(y = Accuracy_Test, color = 'Accuracy Test')) +
  labs(title = "Model Performance with Different Oversampling Ratios",
       x = "Positive Class Ratio",
       y = "Performance Metric") +
  theme_minimal() +
  scale_color_manual(name = "Metric", values = c("F1 Train" = "blue", "F1 Test" = "green", "Accuracy Train" = "red", "Accuracy Test" = "purple"))
```

### SMOTE(Synthetic Minor Over-Sampling Technique)

샘플링 클래스에 해당하는 데이터 포인트를 임의로 선택한 후,

선택한 데이터와 동일 클래스인 k개의 최근접 이웃 데이터 포인트를 구합니다.

k개의 이웃 중 하나를 골라 두 데이터 포인트간 직선 위의 하나의 포인트를 샘플링합니다. 

#### 알고리즘

1. 샘플링 대상 클래스에 해당하는 데이터 포인트를 임의로 선정하고, k개의 동일 클래스인 최근접 이웃 구합니다. 


2. 이웃 중에 무작위로 하나를 선택하고, 두 데이터 포인트를 잇는 선분 상의 임의 포인트를 표본으로 만듭니다.


3. 원하는 수만큼의 표본을 취할 때까지 1부터 반복합니다.


**imblearn.over_sampling import SMOTE**

**주요 하이파라메터**

|이름|설명|
|---|:-----|
|k_neighbors|주변 샘플 수|

**[Ex.3]**

SMOTE 알고리즘이 동작하기 위해 2차원의 클래스가 불균형한 2진 데이터를 만듭니다.

SMOTE 후의 표본이 만들어지는 형태를 확인하여 SMOTE의 표본 생성 메카니즘을 시각화해봅니다.

```{r}
library(MASS)
library("UBL")

# 2차원 데이터 샘플 생성
set.seed(123)
n_samples <- c(200, 10)
centers <- matrix(c(0, 0, 2, 2), ncol = 2, byrow = TRUE)
cluster_std <- c(0.5, 2)

# 데이터 생성
X <- rbind(
  mvrnorm(n_samples[1], centers[1, ], diag(cluster_std[1], 2)),
  mvrnorm(n_samples[2], centers[2, ], diag(cluster_std[2], 2))
)
y <- factor(rep(1:2, n_samples))

# 데이터 프레임 생성
df <- data.frame(X1 = X[, 1], X2 = X[, 2], Class = y)

# SMOTE 적용
df_smote <- SmoteClassif(Class ~ ., df, C.perc = "balance", k = 3)

# 원본 데이터 시각화
p1 <- ggplot(df, aes(x = X1, y = X2, color = Class)) +
  geom_point() +
  ggtitle("Original data") +
  theme_minimal()

# SMOTE 적용 후 데이터 시각화
p2 <- ggplot(df_smote, aes(x = X1, y = X2, color = Class)) +
  geom_point() +
  ggtitle("SMOTE applied data") +
  theme_minimal()

# 시각화
gridExtra::grid.arrange(p1, p2, ncol = 2)
```

**[Ex.4]**

학습 데이터 df_train에서 대상 변수 Class를 제외한 모든 변수를 입력 변수로 설정합니다. 

Class가 양성(Positive)인 비율을 아래와 같이 변화를 주어, 

df_train을 SMOTE 알고리즘으로 Over Sampling하고 성능의 차이를 살펴 봅니다.

이 때 이웃의 수는 5개로 설정합니다.

df_train을 Over Sampling한 데이터로 학습하고, df_test로 성능을 측정합니다.

성능 지표는 f1-score 이고, 학습 모델은 로지스틱 회귀(Logistic Regression)입니다.


postive_ratio = [0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.08, 0.1, 0.15]


```{r}
# 초기화
f1_train_ros <- c()
f1_test_ros <- c()
acc_train <- c()
acc_test <- c()

# 오버샘플링하지 않았을 경우의 성능 기록
result <- eval_model(logistic_reg, df_train, df_test, trace=FALSE)
acc_train <- c(acc_train, result[1])
f1_train_ros <- c(f1_train_ros, result[2])
acc_test <- c(acc_test, result[3])
f1_test_ros <- c(f1_test_ros, result[4])

# 제시한 오버샘플링 비율에 따른 성능 측정
postive_ratio <- c(0.2, 0.25, 0.3, 0.4, 0.5)
ham_cnt = sum(df_train$target == 'ham')
spam_cnt = sum(df_train$target == 'spam')

for (i in postive_ratio) {
  smote_ratios <- list("ham" = 1, "spam" = ham_cnt * i / spam_cnt)
  df_train_ros <- SmoteClassif(target ~ ., df_train, C.perc = smote_ratios, k = 5)
  result <- eval_model(logistic_reg, df_train_ros, df_test, trace=FALSE)
  acc_train <- c(acc_train, result[1])
  f1_train_ros <- c(f1_train_ros, result[2])
  acc_test <- c(acc_test, result[3])
  f1_test_ros <- c(f1_test_ros, result[4])
}

postive_ratio <- c(sum(df_train$target == 'spam') / nrow(df_train), postive_ratio)

# 결과 시각화
results <- data.frame(
  Ratio = c(postive_ratio),
  F1_Train = f1_train_ros,
  F1_Test = f1_test_ros,
  Accuracy_Train = acc_train,
  Accuracy_Test = acc_test
)
```

```{r}
ggplot(results, aes(x = Ratio)) +
  geom_line(aes(y = F1_Train, color = 'F1 Train')) +
  geom_line(aes(y = F1_Test, color = 'F1 Test')) +
  geom_line(aes(y = Accuracy_Train, color = 'Accuracy Train')) +
  geom_line(aes(y = Accuracy_Test, color = 'Accuracy Test')) +
  labs(title = "Model Performance with Different Oversampling Ratios with SMOTE",
       x = "Positive Class Ratio",
       y = "Performance Metric") +
  theme_minimal() +
  scale_color_manual(name = "Metric", values = c("F1 Train" = "blue", "F1 Test" = "green", "Accuracy Train" = "red", "Accuracy Test" = "purple"))
```

### ADASYN(Adaptive Synthetic Sampling)

SMOTE 기법을 보완하여 개발된 알고리즘입니다. 

샘플을 생성하는 수를 샘플 간 거리에 비례하도록 하여 밀도가 낮은 구역에 샘플이 더 확보되도록 합니다.

---
title: "3-4. 클래스 불균형 해소"
output: html_notebook
---

# 3-4. 클래스 불균형 해소(Class Imbalance)


- 클래스 불균형 문제는 클래스의 출현 빈도의 차이가 심한 상태를 의미합니다.


- 클래스의 불균형으로 인한 성능 저하를 완화하기 위한 방법들을 알아봅니다.


- f1 점수(f1 score), 매크로 재현율(Macro recall)과 같이 소수의 클래스의 분류 정확도를 올리면 성능 향상을 기대할 수 있습니다. 클래스 불균형 해소를 통해 성능의 개선 효과를 기대할 수 있습니다.

> $\text{f1 점수(f1 score)} = 2 × \frac{Recall × Precision }{Recall + Precision}$
>
> $\text{매크로 재현율(Macro recall)} = \frac{1}{c}\sum_{i=1}^c \text{Recall}_i$, $\text{Recall}_i$: i 클래스를 양성으로 했을 때의 재현율(Recall)


## 0. 데이터셋 소개

### SMS Spam dataset

[Spam](https://archive.ics.uci.edu/dataset/228/sms+spam+collection):SMS 텍스트로 메세지와 Spam 여부를 나타낸 데이터셋입니다.

|Name|Type|Description|
|----|---|---------|
|target|binary|ham or spam|
|message|text|SMS message|

텍스트를 입력으로 분류를 연습하기 위한 데이터셋입니다.


```{r}
library(readr)

df_sms <- read_tsv("../data/SMSSpamCollection.tsv")
df_sms
```

df_sms에서 message를 모델의 입력으로 사용하기 위해 단어의 최소 출현 빈도를 5로 하여 Bag of Model로 만들고, 

TFIDF을 적용한다음, Latenst Semantic Analysis 모델을 이용하여 4개의 차원으로 축소합니다.

```{r}
library(dplyr)
library(tidyr)
library(tidytext)
library(tm)
library(SnowballC)
library(caret)
library(text2vec)
library(Matrix)
library(slam)


# 데이터 전처리
data_clean <- df_sms %>%
  mutate(message = tolower(message)) %>%
  unnest_tokens(word, message) %>%
  anti_join(stop_words) %>%
  count(target, word, sort = TRUE) %>%
  ungroup()

# 빈도수가 5 이상인 단어만 사용
word_freq <- data_clean %>%
  group_by(word) %>%
  summarize(total = sum(n)) %>%
  filter(total >= 5)

data_filtered <- data_clean %>%
  inner_join(word_freq, by = "word")

# Bag of Words
corpus <- Corpus(VectorSource(df_sms$message))
dtm <- DocumentTermMatrix(corpus, control = list(dictionary = word_freq$word, wordLengths = c(1, Inf)))

# TF-IDF
dtm_tfidf <- DocumentTermMatrix(corpus,
                                control = list(dictionary = word_freq$word, weighting = weightTfIdf, wordLengths = c(1, Inf)))


# LSA 모델 (Latent Semantic Analysis)
dtm_tfidf_matrix <- as.matrix(dtm_tfidf)
lsa_model <- text2vec::LatentSemanticAnalysis$new(n_topics = 4)
doc_topic_matrix <- lsa_model$fit_transform(dtm_tfidf_matrix)

# 데이터셋 준비
df_sms_final <-  cbind(df_sms , doc_topic_matrix) %>% select(-message) %>%
  rename(X1 = 2, X2 = 3, X3 = 4, X4 = 5) %>% mutate(target=factor(target))

df_sms_final
```

## 1. Over sampling

- 빈도가 상대적으로 적은 클래스 데이터를 더 생성하여 불균형을 해소하는 방법입니다.

### Random Over Sampling

샘플할 클래스와 동일한 클래스인 데이터 중에서 임의로 뽑아내는 샘플링 방법입니다.


**[Ex.1]** 

클래스수가 2개인 클래스 불균형 지닌 데이터셋을 만들고,

samping_strategy 설정에 따라 추출된 데이터의 클래스의 개수를 확인하여 OverSampler의 동작을 확인합니다. 

```
[0.1, 0.5, 1.0]
```

```{r}
# 필요한 라이브러리 불러오기
library(mlbench)
library(dplyr)

# 데이터 생성
set.seed(123)
data <- mlbench.2dnormals(n = 5000, cl = 2, sd = 0.8)
df <- as.data.frame(data$x)
df$Class <- as.factor(data$classes)

# 클래스 분포 조정 (불균형 데이터)
class_weights <- c(0.01, 0.99)
sampled_idx <- c(
  sample(which(df$Class == 1), size = round(0.01 * nrow(df)), replace = TRUE),
  sample(which(df$Class == 2), size = round(0.99 * nrow(df)), replace = TRUE)
)
df <- df[sampled_idx, ]

# 클래스 0과 1로 변환
df$Class <- factor(ifelse(df$Class == 1, 0, 1))

# 결과 확인
table(df$Class)

# 시각화
library(ggplot2)
ggplot(df, aes(x = V1, y = V2, color = Class)) +
  geom_point() +
  labs(title = "Generated Classification Data",
       x = "Feature 1", y = "Feature 2") +
  theme_minimal()
```

```{r}
library(ROSE)
library(reshape2)

class_cnt <- list(table(df$Class) %>% as.data.frame() %>% mutate(strategy = 'Original'))

# 다양한 샘플링 전략 적용
for (i in c(0.1, 0.5, 1.0)) {
  print(i)
  df_ros <- ovun.sample(Class ~ ., data = df, method = "over", N = sum(df$Class == 1) + sum(df$Class == 1) * i, seed = 123)$data
  
  class_cnt <- append(
    class_cnt, list(table(df_ros$Class) %>% as.data.frame() %>% mutate(strategy = paste("Sampling strategy:", i)))
  )
}

# 결과 확인
class_cnt_df <- bind_rows(class_cnt) %>%
  rename(Class = Var1) %>%
  select(strategy, Class, Freq) %>%
  dcast(strategy ~ Class, value.var = "Freq")

class_cnt_df
```

**[Ex.2]** 

클래스수가 3개인 클래스 불균형 지닌 데이터셋을 만듭니다.

0번 클래스의 비율은 0.01, 1번 클래스의 비율은 0.97 그리고 2번 클래스의 비율은 0.02 이 되도록 하여 총 5000개의 

데이터를 만듭니다.

samping_strategy 설정에 따라 추출된 데이터의 클래스의 개수를 확인하여 OverSampler의 동작을 확인합니다. 


클래스의 수가 {0: 200, 2: 300} 되도록 Over sampling을 합니다. 


```{r}
# 데이터 생성
set.seed(123)
data <- mlbench::mlbench.2dnormals(n = 5000, cl = 3, sd = 0.8)
df <- as.data.frame(data$x)
df$Class <- as.factor(data$classes)

# 클래스 분포 조정 (불균형 데이터)
class_weights <- c(0.01, 0.97, 0.02)
sampled_idx <- c(
  sample(which(df$Class == 1), size = round(class_weights[1] * nrow(df)), replace = TRUE),
  sample(which(df$Class == 2), size = round(class_weights[2] * nrow(df)), replace = TRUE),
  sample(which(df$Class == 3), size = round(class_weights[3] * nrow(df)), replace = TRUE)
)
df <- df[sampled_idx, ]
```

```{r}
library(ROSE)
library(dplyr)
library(reshape2)

# 원본 클래스 분포 확인
class_cnt <- list(data.frame(table(df$Class)) %>% rename(Freq = Freq) %>% mutate(strategy = 'Original'))

# 특정 클래스 샘플링 전략 적용
# 클래스 0: 200개, 클래스 2: 300개로 오버샘플링
class0_oversampled <- df %>% filter(Class == 1) %>% sample_n(200, replace = TRUE)
class1_oversampled <- df %>% filter(Class == 3) %>% sample_n(300, replace = TRUE)
class2 <- df %>% filter(Class == 2)

# 오버샘플링 된 데이터 결합
df_os <- bind_rows(class0_oversampled, class1_oversampled, class2)

# 새로운 클래스 분포 추가
class_cnt <- append(
  class_cnt, list(data.frame(table(df_os$Class)) %>% rename(Freq = Freq) %>% mutate(strategy = 'Sampling strategy: {0: 200, 2: 300}'))
)

# 결과 확인 및 변환
class_cnt_df <- bind_rows(class_cnt) %>%
  rename(Class = Var1) %>%
  dcast(strategy ~ Class, value.var = "Freq")

# 결과 출력
print(class_cnt_df)
```

이후 클래스 불균형 처리 방법에서 예시를 들기 위한 데이터 처리 작업입니다.

df_sms_final 데이터셋의 타겟 변수인 target의 비율을 동일하게 하여,

80%는 학습데이터 df_train으로, 20%는 평가데이터 df_test로 나눕니다.

target가 'spam'인 경우가 양성(Positive)이고 0이 음성(Negative) 입니다.

```{r}
library(caret)
# 데이터 분할
set.seed(123)
trainIndex <- createDataPartition(df_sms_final$target, p = 0.8, list = FALSE, times = 1)
df_train <- df_sms_final[trainIndex, ]
df_test <- df_sms_final[-trainIndex, ]

# 데이터 분할 결과 확인
table(df_train$target)
table(df_test$target)
```

```{r}
library(nnet)  # for multinom function
X_cols <- setdiff(names(df_train), 'target')

# F1 스코어 함수
F1_Score <- function(pred, actual, positive) {
  cm <- confusionMatrix(pred, actual, mode = "prec_recall", positive = positive)
  f1 = cm[["byClass"]]["F1"][[1]]
  if (is.na(f1)) {
    f1 <- 0
  }
  return(f1)
}

eval_model <- function(clf, df_train, df_test,  ...) {
  # 모델 학습
  model <- clf(df_train[, X_cols], df_train$target, ...)
  # 예측 수행
  pred_train <- predict(model, df_train[, X_cols])
  pred_test <- predict(model, df_test[, X_cols])
  # 정확도 계산
  train_accuracy <- mean(pred_train == df_train$target)
  train_f1 <- F1_Score(pred_train, df_train$target, positive = "spam")
  
  test_accuracy <- mean(pred_test== df_test$target)
  test_f1 <- F1_Score(pred_test, df_test$target, positive = "spam")
  return (c(train_accuracy, train_f1, test_accuracy, test_f1))
}

# 로지스틱 회귀 모델 설정
logistic_reg <- function(X, y, ...) {
  multinom(y ~ ., data = data.frame(X, y), ...)
}

# 초기화
f1_train_ros <- c()
f1_test_ros <- c()
acc_train <- c()
acc_test <- c()

# 오버샘플링하지 않았을 경우의 성능 기록
result <- eval_model(logistic_reg, df_train, df_test, trace=FALSE)
acc_train <- c(acc_train, result[1])
f1_train_ros <- c(f1_train_ros, result[2])
acc_test <- c(acc_test, result[3])
f1_test_ros <- c(f1_test_ros, result[4])

# 제시한 오버샘플링 비율에 따른 성능 측정
postive_ratio <- c(0.2, 0.25, 0.3, 0.4, 0.5)
for (i in postive_ratio) {
  df_train_ros <- ovun.sample(target ~ ., data = df_train, method = "over", N = floor((1 + i) * nrow(df_train)))$data
  result <- eval_model(logistic_reg, df_train_ros, df_test, trace=FALSE)
  acc_train <- c(acc_train, result[1])
  f1_train_ros <- c(f1_train_ros, result[2])
  acc_test <- c(acc_test, result[3])
  f1_test_ros <- c(f1_test_ros, result[4])
}

postive_ratio <- c(sum(df_train$target == 'spam') / nrow(df_train), postive_ratio)

# 결과 시각화
results <- data.frame(
  Ratio = c(postive_ratio),
  F1_Train = f1_train_ros,
  F1_Test = f1_test_ros,
  Accuracy_Train = acc_train,
  Accuracy_Test = acc_test
)
```

```{r}
ggplot(results, aes(x = Ratio)) +
  geom_line(aes(y = F1_Train, color = 'F1 Train')) +
  geom_line(aes(y = F1_Test, color = 'F1 Test')) +
  geom_line(aes(y = Accuracy_Train, color = 'Accuracy Train')) +
  geom_line(aes(y = Accuracy_Test, color = 'Accuracy Test')) +
  labs(title = "Model Performance with Different Oversampling Ratios",
       x = "Positive Class Ratio",
       y = "Performance Metric") +
  theme_minimal() +
  scale_color_manual(name = "Metric", values = c("F1 Train" = "blue", "F1 Test" = "green", "Accuracy Train" = "red", "Accuracy Test" = "purple"))
```

### SMOTE(Synthetic Minor Over-Sampling Technique)

샘플링 클래스에 해당하는 데이터 포인트를 임의로 선택한 후,

선택한 데이터와 동일 클래스인 k개의 최근접 이웃 데이터 포인트를 구합니다.

k개의 이웃 중 하나를 골라 두 데이터 포인트간 직선 위의 하나의 포인트를 샘플링합니다. 

#### 알고리즘

1. 샘플링 대상 클래스에 해당하는 데이터 포인트를 임의로 선정하고, k개의 동일 클래스인 최근접 이웃 구합니다. 


2. 이웃 중에 무작위로 하나를 선택하고, 두 데이터 포인트를 잇는 선분 상의 임의 포인트를 표본으로 만듭니다.


3. 원하는 수만큼의 표본을 취할 때까지 1부터 반복합니다.


**imblearn.over_sampling import SMOTE**

**주요 하이파라메터**

|이름|설명|
|---|:-----|
|k_neighbors|주변 샘플 수|

**[Ex.3]**

SMOTE 알고리즘이 동작하기 위해 2차원의 클래스가 불균형한 2진 데이터를 만듭니다.

SMOTE 후의 표본이 만들어지는 형태를 확인하여 SMOTE의 표본 생성 메카니즘을 시각화해봅니다.

```{r}
library(MASS)
library("UBL")

# 2차원 데이터 샘플 생성
set.seed(123)
n_samples <- c(200, 10)
centers <- matrix(c(0, 0, 2, 2), ncol = 2, byrow = TRUE)
cluster_std <- c(0.5, 2)

# 데이터 생성
X <- rbind(
  mvrnorm(n_samples[1], centers[1, ], diag(cluster_std[1], 2)),
  mvrnorm(n_samples[2], centers[2, ], diag(cluster_std[2], 2))
)
y <- factor(rep(1:2, n_samples))

# 데이터 프레임 생성
df <- data.frame(X1 = X[, 1], X2 = X[, 2], Class = y)

# SMOTE 적용
df_smote <- SmoteClassif(Class ~ ., df, C.perc = "balance", k = 3)

# 원본 데이터 시각화
p1 <- ggplot(df, aes(x = X1, y = X2, color = Class)) +
  geom_point() +
  ggtitle("Original data") +
  theme_minimal()

# SMOTE 적용 후 데이터 시각화
p2 <- ggplot(df_smote, aes(x = X1, y = X2, color = Class)) +
  geom_point() +
  ggtitle("SMOTE applied data") +
  theme_minimal()

# 시각화
gridExtra::grid.arrange(p1, p2, ncol = 2)
```

**[Ex.4]**

학습 데이터 df_train에서 대상 변수 Class를 제외한 모든 변수를 입력 변수로 설정합니다. 

Class가 양성(Positive)인 비율을 아래와 같이 변화를 주어, 

df_train을 SMOTE 알고리즘으로 Over Sampling하고 성능의 차이를 살펴 봅니다.

이 때 이웃의 수는 5개로 설정합니다.

df_train을 Over Sampling한 데이터로 학습하고, df_test로 성능을 측정합니다.

성능 지표는 f1-score 이고, 학습 모델은 로지스틱 회귀(Logistic Regression)입니다.


postive_ratio = [0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.08, 0.1, 0.15]


```{r}
# 초기화
f1_train_ros <- c()
f1_test_ros <- c()
acc_train <- c()
acc_test <- c()

# 오버샘플링하지 않았을 경우의 성능 기록
result <- eval_model(logistic_reg, df_train, df_test, trace=FALSE)
acc_train <- c(acc_train, result[1])
f1_train_ros <- c(f1_train_ros, result[2])
acc_test <- c(acc_test, result[3])
f1_test_ros <- c(f1_test_ros, result[4])

# 제시한 오버샘플링 비율에 따른 성능 측정
postive_ratio <- c(0.2, 0.25, 0.3, 0.4, 0.5)
ham_cnt = sum(df_train$target == 'ham')
spam_cnt = sum(df_train$target == 'spam')

for (i in postive_ratio) {
  smote_ratios <- list("ham" = 1, "spam" = ham_cnt * i / spam_cnt)
  df_train_ros <- SmoteClassif(target ~ ., df_train, C.perc = smote_ratios, k = 5)
  result <- eval_model(logistic_reg, df_train_ros, df_test, trace=FALSE)
  acc_train <- c(acc_train, result[1])
  f1_train_ros <- c(f1_train_ros, result[2])
  acc_test <- c(acc_test, result[3])
  f1_test_ros <- c(f1_test_ros, result[4])
}

postive_ratio <- c(sum(df_train$target == 'spam') / nrow(df_train), postive_ratio)

# 결과 시각화
results <- data.frame(
  Ratio = c(postive_ratio),
  F1_Train = f1_train_ros,
  F1_Test = f1_test_ros,
  Accuracy_Train = acc_train,
  Accuracy_Test = acc_test
)
```

```{r}
ggplot(results, aes(x = Ratio)) +
  geom_line(aes(y = F1_Train, color = 'F1 Train')) +
  geom_line(aes(y = F1_Test, color = 'F1 Test')) +
  geom_line(aes(y = Accuracy_Train, color = 'Accuracy Train')) +
  geom_line(aes(y = Accuracy_Test, color = 'Accuracy Test')) +
  labs(title = "Model Performance with Different Oversampling Ratios with SMOTE",
       x = "Positive Class Ratio",
       y = "Performance Metric") +
  theme_minimal() +
  scale_color_manual(name = "Metric", values = c("F1 Train" = "blue", "F1 Test" = "green", "Accuracy Train" = "red", "Accuracy Test" = "purple"))
```

### ADASYN(Adaptive Synthetic Sampling)

SMOTE 기법을 보완하여 개발된 알고리즘입니다. 

샘플을 생성하는 수를 샘플 간 거리에 비례하도록 하여 밀도가 낮은 구역에 샘플이 더 확보되도록 합니다.


---
title: "3-4. 클래스 불균형 해소"
output: html_notebook
---

# 3-4. 클래스 불균형 해소(Class Imbalance)


- 클래스 불균형 문제는 클래스의 출현 빈도의 차이가 심한 상태를 의미합니다.


- 클래스의 불균형으로 인한 성능 저하를 완화하기 위한 방법들을 알아봅니다.


- f1 점수(f1 score), 매크로 재현율(Macro recall)과 같이 소수의 클래스의 분류 정확도를 올리면 성능 향상을 기대할 수 있습니다. 클래스 불균형 해소를 통해 성능의 개선 효과를 기대할 수 있습니다.

> $\text{f1 점수(f1 score)} = 2 × \frac{Recall × Precision }{Recall + Precision}$
>
> $\text{매크로 재현율(Macro recall)} = \frac{1}{c}\sum_{i=1}^c \text{Recall}_i$, $\text{Recall}_i$: i 클래스를 양성으로 했을 때의 재현율(Recall)


## 0. 데이터셋 소개

### SMS Spam dataset

[Spam](https://archive.ics.uci.edu/dataset/228/sms+spam+collection):SMS 텍스트로 메세지와 Spam 여부를 나타낸 데이터셋입니다.

|Name|Type|Description|
|----|---|---------|
|target|binary|ham or spam|
|message|text|SMS message|

텍스트를 입력으로 분류를 연습하기 위한 데이터셋입니다.


```{r}
library(readr)

df_sms <- read_tsv("../data/SMSSpamCollection.tsv")
df_sms
```

df_sms에서 message를 모델의 입력으로 사용하기 위해 단어의 최소 출현 빈도를 5로 하여 Bag of Model로 만들고, 

TFIDF을 적용한다음, Latenst Semantic Analysis 모델을 이용하여 4개의 차원으로 축소합니다.

```{r}
library(dplyr)
library(tidyr)
library(tidytext)
library(tm)
library(SnowballC)
library(caret)
library(text2vec)
library(Matrix)
library(slam)


# 데이터 전처리
data_clean <- df_sms %>%
  mutate(message = tolower(message)) %>%
  unnest_tokens(word, message) %>%
  anti_join(stop_words) %>%
  count(target, word, sort = TRUE) %>%
  ungroup()

# 빈도수가 5 이상인 단어만 사용
word_freq <- data_clean %>%
  group_by(word) %>%
  summarize(total = sum(n)) %>%
  filter(total >= 5)

data_filtered <- data_clean %>%
  inner_join(word_freq, by = "word")

# Bag of Words
corpus <- Corpus(VectorSource(df_sms$message))
dtm <- DocumentTermMatrix(corpus, control = list(dictionary = word_freq$word, wordLengths = c(1, Inf)))

# TF-IDF
dtm_tfidf <- DocumentTermMatrix(corpus,
                                control = list(dictionary = word_freq$word, weighting = weightTfIdf, wordLengths = c(1, Inf)))


# LSA 모델 (Latent Semantic Analysis)
dtm_tfidf_matrix <- as.matrix(dtm_tfidf)
lsa_model <- text2vec::LatentSemanticAnalysis$new(n_topics = 4)
doc_topic_matrix <- lsa_model$fit_transform(dtm_tfidf_matrix)

# 데이터셋 준비
df_sms_final <-  cbind(df_sms , doc_topic_matrix) %>% select(-message) %>%
  rename(X1 = 2, X2 = 3, X3 = 4, X4 = 5) %>% mutate(target=factor(target))

df_sms_final
```

## 1. Over sampling

- 빈도가 상대적으로 적은 클래스 데이터를 더 생성하여 불균형을 해소하는 방법입니다.

### Random Over Sampling

샘플할 클래스와 동일한 클래스인 데이터 중에서 임의로 뽑아내는 샘플링 방법입니다.


**[Ex.1]** 

클래스수가 2개인 클래스 불균형 지닌 데이터셋을 만들고,

samping_strategy 설정에 따라 추출된 데이터의 클래스의 개수를 확인하여 OverSampler의 동작을 확인합니다. 

```
[0.1, 0.5, 1.0]
```

```{r}
# 필요한 라이브러리 불러오기
library(mlbench)
library(dplyr)

# 데이터 생성
set.seed(123)
data <- mlbench.2dnormals(n = 5000, cl = 2, sd = 0.8)
df <- as.data.frame(data$x)
df$Class <- as.factor(data$classes)

# 클래스 분포 조정 (불균형 데이터)
class_weights <- c(0.01, 0.99)
sampled_idx <- c(
  sample(which(df$Class == 1), size = round(0.01 * nrow(df)), replace = TRUE),
  sample(which(df$Class == 2), size = round(0.99 * nrow(df)), replace = TRUE)
)
df <- df[sampled_idx, ]

# 클래스 0과 1로 변환
df$Class <- factor(ifelse(df$Class == 1, 0, 1))

# 결과 확인
table(df$Class)

# 시각화
library(ggplot2)
ggplot(df, aes(x = V1, y = V2, color = Class)) +
  geom_point() +
  labs(title = "Generated Classification Data",
       x = "Feature 1", y = "Feature 2") +
  theme_minimal()
```

```{r}
library(ROSE)
library(reshape2)

class_cnt <- list(table(df$Class) %>% as.data.frame() %>% mutate(strategy = 'Original'))

# 다양한 샘플링 전략 적용
for (i in c(0.1, 0.5, 1.0)) {
  print(i)
  df_ros <- ovun.sample(Class ~ ., data = df, method = "over", N = sum(df$Class == 1) + sum(df$Class == 1) * i, seed = 123)$data
  
  class_cnt <- append(
    class_cnt, list(table(df_ros$Class) %>% as.data.frame() %>% mutate(strategy = paste("Sampling strategy:", i)))
  )
}

# 결과 확인
class_cnt_df <- bind_rows(class_cnt) %>%
  rename(Class = Var1) %>%
  select(strategy, Class, Freq) %>%
  dcast(strategy ~ Class, value.var = "Freq")

class_cnt_df
```

**[Ex.2]** 

클래스수가 3개인 클래스 불균형 지닌 데이터셋을 만듭니다.

0번 클래스의 비율은 0.01, 1번 클래스의 비율은 0.97 그리고 2번 클래스의 비율은 0.02 이 되도록 하여 총 5000개의 

데이터를 만듭니다.

samping_strategy 설정에 따라 추출된 데이터의 클래스의 개수를 확인하여 OverSampler의 동작을 확인합니다. 


클래스의 수가 {0: 200, 2: 300} 되도록 Over sampling을 합니다. 


```{r}
# 데이터 생성
set.seed(123)
data <- mlbench::mlbench.2dnormals(n = 5000, cl = 3, sd = 0.8)
df <- as.data.frame(data$x)
df$Class <- as.factor(data$classes)

# 클래스 분포 조정 (불균형 데이터)
class_weights <- c(0.01, 0.97, 0.02)
sampled_idx <- c(
  sample(which(df$Class == 1), size = round(class_weights[1] * nrow(df)), replace = TRUE),
  sample(which(df$Class == 2), size = round(class_weights[2] * nrow(df)), replace = TRUE),
  sample(which(df$Class == 3), size = round(class_weights[3] * nrow(df)), replace = TRUE)
)
df <- df[sampled_idx, ]
```

```{r}
library(ROSE)
library(dplyr)
library(reshape2)

# 원본 클래스 분포 확인
class_cnt <- list(data.frame(table(df$Class)) %>% rename(Freq = Freq) %>% mutate(strategy = 'Original'))

# 특정 클래스 샘플링 전략 적용
# 클래스 0: 200개, 클래스 2: 300개로 오버샘플링
class0_oversampled <- df %>% filter(Class == 1) %>% sample_n(200, replace = TRUE)
class1_oversampled <- df %>% filter(Class == 3) %>% sample_n(300, replace = TRUE)
class2 <- df %>% filter(Class == 2)

# 오버샘플링 된 데이터 결합
df_os <- bind_rows(class0_oversampled, class1_oversampled, class2)

# 새로운 클래스 분포 추가
class_cnt <- append(
  class_cnt, list(data.frame(table(df_os$Class)) %>% rename(Freq = Freq) %>% mutate(strategy = 'Sampling strategy: {0: 200, 2: 300}'))
)

# 결과 확인 및 변환
class_cnt_df <- bind_rows(class_cnt) %>%
  rename(Class = Var1) %>%
  dcast(strategy ~ Class, value.var = "Freq")

# 결과 출력
print(class_cnt_df)
```

이후 클래스 불균형 처리 방법에서 예시를 들기 위한 데이터 처리 작업입니다.

df_sms_final 데이터셋의 타겟 변수인 target의 비율을 동일하게 하여,

80%는 학습데이터 df_train으로, 20%는 평가데이터 df_test로 나눕니다.

target가 'spam'인 경우가 양성(Positive)이고 0이 음성(Negative) 입니다.

```{r}
library(caret)
# 데이터 분할
set.seed(123)
trainIndex <- createDataPartition(df_sms_final$target, p = 0.8, list = FALSE, times = 1)
df_train <- df_sms_final[trainIndex, ]
df_test <- df_sms_final[-trainIndex, ]

# 데이터 분할 결과 확인
table(df_train$target)
table(df_test$target)
```

```{r}
library(nnet)  # for multinom function
X_cols <- setdiff(names(df_train), 'target')

# F1 스코어 함수
F1_Score <- function(pred, actual, positive) {
  cm <- confusionMatrix(pred, actual, mode = "prec_recall", positive = positive)
  f1 = cm[["byClass"]]["F1"][[1]]
  if (is.na(f1)) {
    f1 <- 0
  }
  return(f1)
}

eval_model <- function(clf, df_train, df_test,  ...) {
  # 모델 학습
  model <- clf(df_train[, X_cols], df_train$target, ...)
  # 예측 수행
  pred_train <- predict(model, df_train[, X_cols])
  pred_test <- predict(model, df_test[, X_cols])
  # 정확도 계산
  train_accuracy <- mean(pred_train == df_train$target)
  train_f1 <- F1_Score(pred_train, df_train$target, positive = "spam")
  
  test_accuracy <- mean(pred_test== df_test$target)
  test_f1 <- F1_Score(pred_test, df_test$target, positive = "spam")
  return (c(train_accuracy, train_f1, test_accuracy, test_f1))
}

# 로지스틱 회귀 모델 설정
logistic_reg <- function(X, y, ...) {
  multinom(y ~ ., data = data.frame(X, y), ...)
}

# 초기화
f1_train_ros <- c()
f1_test_ros <- c()
acc_train <- c()
acc_test <- c()

# 오버샘플링하지 않았을 경우의 성능 기록
result <- eval_model(logistic_reg, df_train, df_test, trace=FALSE)
acc_train <- c(acc_train, result[1])
f1_train_ros <- c(f1_train_ros, result[2])
acc_test <- c(acc_test, result[3])
f1_test_ros <- c(f1_test_ros, result[4])

# 제시한 오버샘플링 비율에 따른 성능 측정
postive_ratio <- c(0.2, 0.25, 0.3, 0.4, 0.5)
for (i in postive_ratio) {
  df_train_ros <- ovun.sample(target ~ ., data = df_train, method = "over", N = floor((1 + i) * nrow(df_train)))$data
  result <- eval_model(logistic_reg, df_train_ros, df_test, trace=FALSE)
  acc_train <- c(acc_train, result[1])
  f1_train_ros <- c(f1_train_ros, result[2])
  acc_test <- c(acc_test, result[3])
  f1_test_ros <- c(f1_test_ros, result[4])
}

postive_ratio <- c(sum(df_train$target == 'spam') / nrow(df_train), postive_ratio)

# 결과 시각화
results <- data.frame(
  Ratio = c(postive_ratio),
  F1_Train = f1_train_ros,
  F1_Test = f1_test_ros,
  Accuracy_Train = acc_train,
  Accuracy_Test = acc_test
)
```

```{r}
ggplot(results, aes(x = Ratio)) +
  geom_line(aes(y = F1_Train, color = 'F1 Train')) +
  geom_line(aes(y = F1_Test, color = 'F1 Test')) +
  geom_line(aes(y = Accuracy_Train, color = 'Accuracy Train')) +
  geom_line(aes(y = Accuracy_Test, color = 'Accuracy Test')) +
  labs(title = "Model Performance with Different Oversampling Ratios",
       x = "Positive Class Ratio",
       y = "Performance Metric") +
  theme_minimal() +
  scale_color_manual(name = "Metric", values = c("F1 Train" = "blue", "F1 Test" = "green", "Accuracy Train" = "red", "Accuracy Test" = "purple"))
```

### SMOTE(Synthetic Minor Over-Sampling Technique)

샘플링 클래스에 해당하는 데이터 포인트를 임의로 선택한 후,

선택한 데이터와 동일 클래스인 k개의 최근접 이웃 데이터 포인트를 구합니다.

k개의 이웃 중 하나를 골라 두 데이터 포인트간 직선 위의 하나의 포인트를 샘플링합니다. 

#### 알고리즘

1. 샘플링 대상 클래스에 해당하는 데이터 포인트를 임의로 선정하고, k개의 동일 클래스인 최근접 이웃 구합니다. 


2. 이웃 중에 무작위로 하나를 선택하고, 두 데이터 포인트를 잇는 선분 상의 임의 포인트를 표본으로 만듭니다.


3. 원하는 수만큼의 표본을 취할 때까지 1부터 반복합니다.


**imblearn.over_sampling import SMOTE**

**주요 하이파라메터**

|이름|설명|
|---|:-----|
|k_neighbors|주변 샘플 수|

**[Ex.3]**

SMOTE 알고리즘이 동작하기 위해 2차원의 클래스가 불균형한 2진 데이터를 만듭니다.

SMOTE 후의 표본이 만들어지는 형태를 확인하여 SMOTE의 표본 생성 메카니즘을 시각화해봅니다.

```{r}
library(MASS)
library("UBL")

# 2차원 데이터 샘플 생성
set.seed(123)
n_samples <- c(200, 10)
centers <- matrix(c(0, 0, 2, 2), ncol = 2, byrow = TRUE)
cluster_std <- c(0.5, 2)

# 데이터 생성
X <- rbind(
  mvrnorm(n_samples[1], centers[1, ], diag(cluster_std[1], 2)),
  mvrnorm(n_samples[2], centers[2, ], diag(cluster_std[2], 2))
)
y <- factor(rep(1:2, n_samples))

# 데이터 프레임 생성
df <- data.frame(X1 = X[, 1], X2 = X[, 2], Class = y)

# SMOTE 적용
df_smote <- SmoteClassif(Class ~ ., df, C.perc = "balance", k = 3)

# 원본 데이터 시각화
p1 <- ggplot(df, aes(x = X1, y = X2, color = Class)) +
  geom_point() +
  ggtitle("Original data") +
  theme_minimal()

# SMOTE 적용 후 데이터 시각화
p2 <- ggplot(df_smote, aes(x = X1, y = X2, color = Class)) +
  geom_point() +
  ggtitle("SMOTE applied data") +
  theme_minimal()

# 시각화
gridExtra::grid.arrange(p1, p2, ncol = 2)
```

**[Ex.4]**

학습 데이터 df_train에서 대상 변수 Class를 제외한 모든 변수를 입력 변수로 설정합니다. 

Class가 양성(Positive)인 비율을 아래와 같이 변화를 주어, 

df_train을 SMOTE 알고리즘으로 Over Sampling하고 성능의 차이를 살펴 봅니다.

이 때 이웃의 수는 5개로 설정합니다.

df_train을 Over Sampling한 데이터로 학습하고, df_test로 성능을 측정합니다.

성능 지표는 f1-score 이고, 학습 모델은 로지스틱 회귀(Logistic Regression)입니다.


postive_ratio = [0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.08, 0.1, 0.15]


```{r}
# 초기화
f1_train_ros <- c()
f1_test_ros <- c()
acc_train <- c()
acc_test <- c()

# 오버샘플링하지 않았을 경우의 성능 기록
result <- eval_model(logistic_reg, df_train, df_test, trace=FALSE)
acc_train <- c(acc_train, result[1])
f1_train_ros <- c(f1_train_ros, result[2])
acc_test <- c(acc_test, result[3])
f1_test_ros <- c(f1_test_ros, result[4])

# 제시한 오버샘플링 비율에 따른 성능 측정
postive_ratio <- c(0.2, 0.25, 0.3, 0.4, 0.5)
ham_cnt = sum(df_train$target == 'ham')
spam_cnt = sum(df_train$target == 'spam')

for (i in postive_ratio) {
  smote_ratios <- list("ham" = 1, "spam" = ham_cnt * i / spam_cnt)
  df_train_ros <- SmoteClassif(target ~ ., df_train, C.perc = smote_ratios, k = 5)
  result <- eval_model(logistic_reg, df_train_ros, df_test, trace=FALSE)
  acc_train <- c(acc_train, result[1])
  f1_train_ros <- c(f1_train_ros, result[2])
  acc_test <- c(acc_test, result[3])
  f1_test_ros <- c(f1_test_ros, result[4])
}

postive_ratio <- c(sum(df_train$target == 'spam') / nrow(df_train), postive_ratio)

# 결과 시각화
results <- data.frame(
  Ratio = c(postive_ratio),
  F1_Train = f1_train_ros,
  F1_Test = f1_test_ros,
  Accuracy_Train = acc_train,
  Accuracy_Test = acc_test
)
```

```{r}
ggplot(results, aes(x = Ratio)) +
  geom_line(aes(y = F1_Train, color = 'F1 Train')) +
  geom_line(aes(y = F1_Test, color = 'F1 Test')) +
  geom_line(aes(y = Accuracy_Train, color = 'Accuracy Train')) +
  geom_line(aes(y = Accuracy_Test, color = 'Accuracy Test')) +
  labs(title = "Model Performance with Different Oversampling Ratios with SMOTE",
       x = "Positive Class Ratio",
       y = "Performance Metric") +
  theme_minimal() +
  scale_color_manual(name = "Metric", values = c("F1 Train" = "blue", "F1 Test" = "green", "Accuracy Train" = "red", "Accuracy Test" = "purple"))
```

### ADASYN(Adaptive Synthetic Sampling)

SMOTE 기법을 보완하여 개발된 알고리즘입니다. 

샘플을 생성하는 수를 샘플 간 거리에 비례하도록 하여 밀도가 낮은 구역에 샘플이 더 확보되도록 합니다.

---
title: "3-4. 클래스 불균형 해소"
output: html_notebook
---

# 3-4. 클래스 불균형 해소(Class Imbalance)


- 클래스 불균형 문제는 클래스의 출현 빈도의 차이가 심한 상태를 의미합니다.


- 클래스의 불균형으로 인한 성능 저하를 완화하기 위한 방법들을 알아봅니다.


- f1 점수(f1 score), 매크로 재현율(Macro recall)과 같이 소수의 클래스의 분류 정확도를 올리면 성능 향상을 기대할 수 있습니다. 클래스 불균형 해소를 통해 성능의 개선 효과를 기대할 수 있습니다.

> $\text{f1 점수(f1 score)} = 2 × \frac{Recall × Precision }{Recall + Precision}$
>
> $\text{매크로 재현율(Macro recall)} = \frac{1}{c}\sum_{i=1}^c \text{Recall}_i$, $\text{Recall}_i$: i 클래스를 양성으로 했을 때의 재현율(Recall)


## 0. 데이터셋 소개

### SMS Spam dataset

[Spam](https://archive.ics.uci.edu/dataset/228/sms+spam+collection):SMS 텍스트로 메세지와 Spam 여부를 나타낸 데이터셋입니다.

|Name|Type|Description|
|----|---|---------|
|target|binary|ham or spam|
|message|text|SMS message|

텍스트를 입력으로 분류를 연습하기 위한 데이터셋입니다.


```{r}
library(readr)

df_sms <- read_tsv("../data/SMSSpamCollection.tsv")
df_sms
```

df_sms에서 message를 모델의 입력으로 사용하기 위해 단어의 최소 출현 빈도를 5로 하여 Bag of Model로 만들고, 

TFIDF을 적용한다음, Latenst Semantic Analysis 모델을 이용하여 4개의 차원으로 축소합니다.

```{r}
library(dplyr)
library(tidyr)
library(tidytext)
library(tm)
library(SnowballC)
library(caret)
library(text2vec)
library(Matrix)
library(slam)


# 데이터 전처리
data_clean <- df_sms %>%
  mutate(message = tolower(message)) %>%
  unnest_tokens(word, message) %>%
  anti_join(stop_words) %>%
  count(target, word, sort = TRUE) %>%
  ungroup()

# 빈도수가 5 이상인 단어만 사용
word_freq <- data_clean %>%
  group_by(word) %>%
  summarize(total = sum(n)) %>%
  filter(total >= 5)

data_filtered <- data_clean %>%
  inner_join(word_freq, by = "word")

# Bag of Words
corpus <- Corpus(VectorSource(df_sms$message))
dtm <- DocumentTermMatrix(corpus, control = list(dictionary = word_freq$word, wordLengths = c(1, Inf)))

# TF-IDF
dtm_tfidf <- DocumentTermMatrix(corpus,
                                control = list(dictionary = word_freq$word, weighting = weightTfIdf, wordLengths = c(1, Inf)))


# LSA 모델 (Latent Semantic Analysis)
dtm_tfidf_matrix <- as.matrix(dtm_tfidf)
lsa_model <- text2vec::LatentSemanticAnalysis$new(n_topics = 4)
doc_topic_matrix <- lsa_model$fit_transform(dtm_tfidf_matrix)

# 데이터셋 준비
df_sms_final <-  cbind(df_sms , doc_topic_matrix) %>% select(-message) %>%
  rename(X1 = 2, X2 = 3, X3 = 4, X4 = 5) %>% mutate(target=factor(target))

df_sms_final
```

## 1. Over sampling

- 빈도가 상대적으로 적은 클래스 데이터를 더 생성하여 불균형을 해소하는 방법입니다.

### Random Over Sampling

샘플할 클래스와 동일한 클래스인 데이터 중에서 임의로 뽑아내는 샘플링 방법입니다.


**[Ex.1]** 

클래스수가 2개인 클래스 불균형 지닌 데이터셋을 만들고,

samping_strategy 설정에 따라 추출된 데이터의 클래스의 개수를 확인하여 OverSampler의 동작을 확인합니다. 

```
[0.1, 0.5, 1.0]
```

```{r}
# 필요한 라이브러리 불러오기
library(mlbench)
library(dplyr)

# 데이터 생성
set.seed(123)
data <- mlbench.2dnormals(n = 5000, cl = 2, sd = 0.8)
df <- as.data.frame(data$x)
df$Class <- as.factor(data$classes)

# 클래스 분포 조정 (불균형 데이터)
class_weights <- c(0.01, 0.99)
sampled_idx <- c(
  sample(which(df$Class == 1), size = round(0.01 * nrow(df)), replace = TRUE),
  sample(which(df$Class == 2), size = round(0.99 * nrow(df)), replace = TRUE)
)
df <- df[sampled_idx, ]

# 클래스 0과 1로 변환
df$Class <- factor(ifelse(df$Class == 1, 0, 1))

# 결과 확인
table(df$Class)

# 시각화
library(ggplot2)
ggplot(df, aes(x = V1, y = V2, color = Class)) +
  geom_point() +
  labs(title = "Generated Classification Data",
       x = "Feature 1", y = "Feature 2") +
  theme_minimal()
```

```{r}
library(ROSE)
library(reshape2)

class_cnt <- list(table(df$Class) %>% as.data.frame() %>% mutate(strategy = 'Original'))

# 다양한 샘플링 전략 적용
for (i in c(0.1, 0.5, 1.0)) {
  print(i)
  df_ros <- ovun.sample(Class ~ ., data = df, method = "over", N = sum(df$Class == 1) + sum(df$Class == 1) * i, seed = 123)$data
  
  class_cnt <- append(
    class_cnt, list(table(df_ros$Class) %>% as.data.frame() %>% mutate(strategy = paste("Sampling strategy:", i)))
  )
}

# 결과 확인
class_cnt_df <- bind_rows(class_cnt) %>%
  rename(Class = Var1) %>%
  select(strategy, Class, Freq) %>%
  dcast(strategy ~ Class, value.var = "Freq")

class_cnt_df
```

**[Ex.2]** 

클래스수가 3개인 클래스 불균형 지닌 데이터셋을 만듭니다.

0번 클래스의 비율은 0.01, 1번 클래스의 비율은 0.97 그리고 2번 클래스의 비율은 0.02 이 되도록 하여 총 5000개의 

데이터를 만듭니다.

samping_strategy 설정에 따라 추출된 데이터의 클래스의 개수를 확인하여 OverSampler의 동작을 확인합니다. 


클래스의 수가 {0: 200, 2: 300} 되도록 Over sampling을 합니다. 


```{r}
# 데이터 생성
set.seed(123)
data <- mlbench::mlbench.2dnormals(n = 5000, cl = 3, sd = 0.8)
df <- as.data.frame(data$x)
df$Class <- as.factor(data$classes)

# 클래스 분포 조정 (불균형 데이터)
class_weights <- c(0.01, 0.97, 0.02)
sampled_idx <- c(
  sample(which(df$Class == 1), size = round(class_weights[1] * nrow(df)), replace = TRUE),
  sample(which(df$Class == 2), size = round(class_weights[2] * nrow(df)), replace = TRUE),
  sample(which(df$Class == 3), size = round(class_weights[3] * nrow(df)), replace = TRUE)
)
df <- df[sampled_idx, ]
```

```{r}
library(ROSE)
library(dplyr)
library(reshape2)

# 원본 클래스 분포 확인
class_cnt <- list(data.frame(table(df$Class)) %>% rename(Freq = Freq) %>% mutate(strategy = 'Original'))

# 특정 클래스 샘플링 전략 적용
# 클래스 0: 200개, 클래스 2: 300개로 오버샘플링
class0_oversampled <- df %>% filter(Class == 1) %>% sample_n(200, replace = TRUE)
class1_oversampled <- df %>% filter(Class == 3) %>% sample_n(300, replace = TRUE)
class2 <- df %>% filter(Class == 2)

# 오버샘플링 된 데이터 결합
df_os <- bind_rows(class0_oversampled, class1_oversampled, class2)

# 새로운 클래스 분포 추가
class_cnt <- append(
  class_cnt, list(data.frame(table(df_os$Class)) %>% rename(Freq = Freq) %>% mutate(strategy = 'Sampling strategy: {0: 200, 2: 300}'))
)

# 결과 확인 및 변환
class_cnt_df <- bind_rows(class_cnt) %>%
  rename(Class = Var1) %>%
  dcast(strategy ~ Class, value.var = "Freq")

# 결과 출력
print(class_cnt_df)
```

이후 클래스 불균형 처리 방법에서 예시를 들기 위한 데이터 처리 작업입니다.

df_sms_final 데이터셋의 타겟 변수인 target의 비율을 동일하게 하여,

80%는 학습데이터 df_train으로, 20%는 평가데이터 df_test로 나눕니다.

target가 'spam'인 경우가 양성(Positive)이고 0이 음성(Negative) 입니다.

```{r}
library(caret)
# 데이터 분할
set.seed(123)
trainIndex <- createDataPartition(df_sms_final$target, p = 0.8, list = FALSE, times = 1)
df_train <- df_sms_final[trainIndex, ]
df_test <- df_sms_final[-trainIndex, ]

# 데이터 분할 결과 확인
table(df_train$target)
table(df_test$target)
```

```{r}
library(nnet)  # for multinom function
X_cols <- setdiff(names(df_train), 'target')

# F1 스코어 함수
F1_Score <- function(pred, actual, positive) {
  cm <- confusionMatrix(pred, actual, mode = "prec_recall", positive = positive)
  f1 = cm[["byClass"]]["F1"][[1]]
  if (is.na(f1)) {
    f1 <- 0
  }
  return(f1)
}

eval_model <- function(clf, df_train, df_test,  ...) {
  # 모델 학습
  model <- clf(df_train[, X_cols], df_train$target, ...)
  # 예측 수행
  pred_train <- predict(model, df_train[, X_cols])
  pred_test <- predict(model, df_test[, X_cols])
  # 정확도 계산
  train_accuracy <- mean(pred_train == df_train$target)
  train_f1 <- F1_Score(pred_train, df_train$target, positive = "spam")
  
  test_accuracy <- mean(pred_test== df_test$target)
  test_f1 <- F1_Score(pred_test, df_test$target, positive = "spam")
  return (c(train_accuracy, train_f1, test_accuracy, test_f1))
}

# 로지스틱 회귀 모델 설정
logistic_reg <- function(X, y, ...) {
  multinom(y ~ ., data = data.frame(X, y), ...)
}

# 초기화
f1_train_ros <- c()
f1_test_ros <- c()
acc_train <- c()
acc_test <- c()

# 오버샘플링하지 않았을 경우의 성능 기록
result <- eval_model(logistic_reg, df_train, df_test, trace=FALSE)
acc_train <- c(acc_train, result[1])
f1_train_ros <- c(f1_train_ros, result[2])
acc_test <- c(acc_test, result[3])
f1_test_ros <- c(f1_test_ros, result[4])

# 제시한 오버샘플링 비율에 따른 성능 측정
postive_ratio <- c(0.2, 0.25, 0.3, 0.4, 0.5)

ham_cnt = sum(df_train$target == 'ham')
spam_cnt = sum(df_train$target == 'spam')

for (i in postive_ratio) {
  df_train_ros <- ovun.sample(target ~ ., data = df_train, method = "over", N = floor((1 + i) * ham_cnt))$data
  result <- eval_model(logistic_reg, df_train_ros, df_test, trace=FALSE)
  acc_train <- c(acc_train, result[1])
  f1_train_ros <- c(f1_train_ros, result[2])
  acc_test <- c(acc_test, result[3])
  f1_test_ros <- c(f1_test_ros, result[4])
}

postive_ratio <- c(sum(df_train$target == 'spam') / nrow(df_train), postive_ratio)

# 결과 시각화
results <- data.frame(
  Ratio = c(postive_ratio),
  F1_Train = f1_train_ros,
  F1_Test = f1_test_ros,
  Accuracy_Train = acc_train,
  Accuracy_Test = acc_test
)
```

```{r}
ggplot(results, aes(x = Ratio)) +
  geom_line(aes(y = F1_Train, color = 'F1 Train')) +
  geom_line(aes(y = F1_Test, color = 'F1 Test')) +
  geom_line(aes(y = Accuracy_Train, color = 'Accuracy Train')) +
  geom_line(aes(y = Accuracy_Test, color = 'Accuracy Test')) +
  labs(title = "Model Performance with Different Oversampling Ratios",
       x = "Positive Class Ratio",
       y = "Performance Metric") +
  theme_minimal() +
  scale_color_manual(name = "Metric", values = c("F1 Train" = "blue", "F1 Test" = "green", "Accuracy Train" = "red", "Accuracy Test" = "purple"))
```

### SMOTE(Synthetic Minor Over-Sampling Technique)

샘플링 클래스에 해당하는 데이터 포인트를 임의로 선택한 후,

선택한 데이터와 동일 클래스인 k개의 최근접 이웃 데이터 포인트를 구합니다.

k개의 이웃 중 하나를 골라 두 데이터 포인트간 직선 위의 하나의 포인트를 샘플링합니다. 

#### 알고리즘

1. 샘플링 대상 클래스에 해당하는 데이터 포인트를 임의로 선정하고, k개의 동일 클래스인 최근접 이웃 구합니다. 


2. 이웃 중에 무작위로 하나를 선택하고, 두 데이터 포인트를 잇는 선분 상의 임의 포인트를 표본으로 만듭니다.


3. 원하는 수만큼의 표본을 취할 때까지 1부터 반복합니다.


**imblearn.over_sampling import SMOTE**

**주요 하이파라메터**

|이름|설명|
|---|:-----|
|k_neighbors|주변 샘플 수|

**[Ex.3]**

SMOTE 알고리즘이 동작하기 위해 2차원의 클래스가 불균형한 2진 데이터를 만듭니다.

SMOTE 후의 표본이 만들어지는 형태를 확인하여 SMOTE의 표본 생성 메카니즘을 시각화해봅니다.

```{r}
library(MASS)
library("UBL")

# 2차원 데이터 샘플 생성
set.seed(123)
n_samples <- c(200, 10)
centers <- matrix(c(0, 0, 2, 2), ncol = 2, byrow = TRUE)
cluster_std <- c(0.5, 2)

# 데이터 생성
X <- rbind(
  mvrnorm(n_samples[1], centers[1, ], diag(cluster_std[1], 2)),
  mvrnorm(n_samples[2], centers[2, ], diag(cluster_std[2], 2))
)
y <- factor(rep(1:2, n_samples))

# 데이터 프레임 생성
df <- data.frame(X1 = X[, 1], X2 = X[, 2], Class = y)

# SMOTE 적용
df_smote <- SmoteClassif(Class ~ ., df, C.perc = "balance", k = 3)

# 원본 데이터 시각화
p1 <- ggplot(df, aes(x = X1, y = X2, color = Class)) +
  geom_point() +
  ggtitle("Original data") +
  theme_minimal()

# SMOTE 적용 후 데이터 시각화
p2 <- ggplot(df_smote, aes(x = X1, y = X2, color = Class)) +
  geom_point() +
  ggtitle("SMOTE applied data") +
  theme_minimal()

# 시각화
gridExtra::grid.arrange(p1, p2, ncol = 2)
```

**[Ex.4]**

학습 데이터 df_train에서 대상 변수 Class를 제외한 모든 변수를 입력 변수로 설정합니다. 

Class가 양성(Positive)인 비율을 아래와 같이 변화를 주어, 

df_train을 SMOTE 알고리즘으로 Over Sampling하고 성능의 차이를 살펴 봅니다.

이 때 이웃의 수는 5개로 설정합니다.

df_train을 Over Sampling한 데이터로 학습하고, df_test로 성능을 측정합니다.

성능 지표는 f1-score 이고, 학습 모델은 로지스틱 회귀(Logistic Regression)입니다.


postive_ratio = c(0.2, 0.25, 0.3, 0.4, 0.5)


```{r}
# 초기화
f1_train_ros <- c()
f1_test_ros <- c()
acc_train <- c()
acc_test <- c()

# 오버샘플링하지 않았을 경우의 성능 기록
result <- eval_model(logistic_reg, df_train, df_test, trace=FALSE)
acc_train <- c(acc_train, result[1])
f1_train_ros <- c(f1_train_ros, result[2])
acc_test <- c(acc_test, result[3])
f1_test_ros <- c(f1_test_ros, result[4])

# 제시한 오버샘플링 비율에 따른 성능 측정
postive_ratio <- c(0.2, 0.25, 0.3, 0.4, 0.5)
ham_cnt = sum(df_train$target == 'ham')
spam_cnt = sum(df_train$target == 'spam')

for (i in postive_ratio) {
  smote_ratios <- list("ham" = 1, "spam" = ham_cnt * i / spam_cnt)
  df_train_ros <- SmoteClassif(target ~ ., df_train, C.perc = smote_ratios, k = 5)
  result <- eval_model(logistic_reg, df_train_ros, df_test, trace=FALSE)
  acc_train <- c(acc_train, result[1])
  f1_train_ros <- c(f1_train_ros, result[2])
  acc_test <- c(acc_test, result[3])
  f1_test_ros <- c(f1_test_ros, result[4])
}

postive_ratio <- c(sum(df_train$target == 'spam') / nrow(df_train), postive_ratio)

# 결과 시각화
results <- data.frame(
  Ratio = c(postive_ratio),
  F1_Train = f1_train_ros,
  F1_Test = f1_test_ros,
  Accuracy_Train = acc_train,
  Accuracy_Test = acc_test
)
```

```{r}
ggplot(results, aes(x = Ratio)) +
  geom_line(aes(y = F1_Train, color = 'F1 Train')) +
  geom_line(aes(y = F1_Test, color = 'F1 Test')) +
  geom_line(aes(y = Accuracy_Train, color = 'Accuracy Train')) +
  geom_line(aes(y = Accuracy_Test, color = 'Accuracy Test')) +
  labs(title = "Model Performance with Different Oversampling Ratios with SMOTE",
       x = "Positive Class Ratio",
       y = "Performance Metric") +
  theme_minimal() +
  scale_color_manual(name = "Metric", values = c("F1 Train" = "blue", "F1 Test" = "green", "Accuracy Train" = "red", "Accuracy Test" = "purple"))
```

### ADASYN(Adaptive Synthetic Sampling)

SMOTE 기법을 보완하여 개발된 알고리즘입니다. 

샘플을 생성하는 수를 샘플 간 거리에 비례하도록 하여 밀도가 낮은 구역에 샘플이 더 확보되도록 합니다.


```{r}
library(MASS)

# 2차원 데이터 샘플 생성
set.seed(123)
n_samples <- c(200, 10)
centers <- matrix(c(0, 0, 2, 2), ncol = 2, byrow = TRUE)
cluster_std <- c(0.5, 2)

# 데이터 생성
X <- rbind(
  mvrnorm(n_samples[1], centers[1, ], diag(cluster_std[1], 2)),
  mvrnorm(n_samples[2], centers[2, ], diag(cluster_std[2], 2))
)
y <- factor(rep(1:2, n_samples))

# 데이터 프레임 생성
df <- data.frame(X1 = X[, 1], X2 = X[, 2], Class = y)

# ADASYN 적용
df_adasyn <- AdasynClassif(Class ~ ., df, beta = list("2"=1.0), baseClass="1", k = 3)

# 원본 데이터 시각화
p1 <- ggplot(df, aes(x = X1, y = X2, color = Class)) +
  geom_point() +
  ggtitle("Original data") +
  theme_minimal()

# SMOTE 적용 후 데이터 시각화
p2 <- ggplot(df_adasyn, aes(x = X1, y = X2, color = Class)) +
  geom_point() +
  ggtitle("ADASYN applied data") +
  theme_minimal()

# 시각화
gridExtra::grid.arrange(p1, p2, ncol = 2)
```

**[Ex.5]**

학습 데이터 df_train에서 대상 변수 Class를 제외한 모든 변수를 입력 변수로 설정합니다. 

Class가 양성(Positive)인 비율을 아래와 같이 변화를 주어 df_train을 ADASYN 알고리즘으로 

Over Sampling하고 성능의 차이를 살펴 봅니다.

Over Sampling한 데이터로 학습을하고, df_test로 성능을 측정합니다.

성능 지표는 f1-score 이고, 학습 모델은 로지스틱 회귀(Logistic Regression)입니다.


postive_ratio = c(0.2, 0.25, 0.3, 0.4, 0.5)


```{r}
# 초기화
f1_train_ros <- c()
f1_test_ros <- c()
acc_train <- c()
acc_test <- c()

# 오버샘플링하지 않았을 경우의 성능 기록
result <- eval_model(logistic_reg, df_train, df_test, trace=FALSE)
acc_train <- c(acc_train, result[1])
f1_train_ros <- c(f1_train_ros, result[2])
acc_test <- c(acc_test, result[3])
f1_test_ros <- c(f1_test_ros, result[4])

# 제시한 오버샘플링 비율에 따른 성능 측정
postive_ratio <- c(0.2, 0.25, 0.3, 0.4, 0.5)
ham_cnt = sum(df_train$target == 'ham')
spam_cnt = sum(df_train$target == 'spam')

for (i in postive_ratio) {
  df_train_ros <- AdasynClassif(target ~ ., df_train, beta = list("spam"=1.0), baseClass="ham", k = 5)
  result <- eval_model(logistic_reg, df_train_ros, df_test, trace=FALSE)
  acc_train <- c(acc_train, result[1])
  f1_train_ros <- c(f1_train_ros, result[2])
  acc_test <- c(acc_test, result[3])
  f1_test_ros <- c(f1_test_ros, result[4])
}

postive_ratio <- c(sum(df_train$target == 'spam') / nrow(df_train), postive_ratio)

# 결과 시각화
results <- data.frame(
  Ratio = c(postive_ratio),
  F1_Train = f1_train_ros,
  F1_Test = f1_test_ros,
  Accuracy_Train = acc_train,
  Accuracy_Test = acc_test
)
```

```{r}
ggplot(results, aes(x = Ratio)) +
  geom_line(aes(y = F1_Train, color = 'F1 Train')) +
  geom_line(aes(y = F1_Test, color = 'F1 Test')) +
  geom_line(aes(y = Accuracy_Train, color = 'Accuracy Train')) +
  geom_line(aes(y = Accuracy_Test, color = 'Accuracy Test')) +
  labs(title = "Model Performance with Different Oversampling Ratios with ADASYN",
       x = "Positive Class Ratio",
       y = "Performance Metric") +
  theme_minimal() +
  scale_color_manual(name = "Metric", values = c("F1 Train" = "blue", "F1 Test" = "green", "Accuracy Train" = "red", "Accuracy Test" = "purple"))
```

### 오버 샘플링의 장단점

#### 장점

- 정보 보존: 소수 클래스의 샘플을 합성하거나 복제하여 데이터의 소수 클래스의 데이터의 특성이 드러나게 하여 정보의 보존 효과를 줍니다.

#### 단점

- 소수 클래스의 샘플을 과도하게 증가시키면 과적합을 유발시킬 수 있습니다.


- 샘플이 증가함에 따라 학습시 계산 비용이 증가합니다.

## 2. Under sampling

- 다수 클래스(Major class)의 데이터를 줄여 불균형을 해소하는 방법입니다.

### Random Under Sampling

샘플링 클래스의 데이터를 임의로 선정하여 대상에서 제외시키는 샘플링 방법입니다.

**[Ex.6]** 

클래스수가 2개인 클래스 불균형 지닌  임의의 데이터셋을 만들고,

samping_strategy 설정에 따라 추출된 데이터의 클래스의 개수를 확인하여 UnderSampler의 동작을 확인합니다. 


[0.1, 0.5, 1.0]


```{r}
library(ROSE)
library(reshape2)

class_cnt <- list(table(df$Class) %>% as.data.frame() %>% mutate(strategy = 'Original'))

# 다양한 샘플링 전략 적용
for (i in c(0.1, 0.5, 1.0)) {
  df_rus <- ovun.sample(Class ~ ., data = df, method = "under", N = sum(df$Class == 2) + sum(df$Class == 2) * (1 / i), seed = 123)$data
  
  class_cnt <- append(
    class_cnt, list(table(df_rus$Class) %>% as.data.frame() %>% mutate(strategy = paste("Sampling strategy:", i)))
  )
}

# 결과 확인
class_cnt_df <- bind_rows(class_cnt) %>%
  rename(Class = Var1) %>%
  dcast(strategy ~ Class, value.var = "Freq")

class_cnt_df
```

**[Ex.7]**

학습 데이터 df_train에서 대상 변수 Class를 제외한 모든 변수를 입력 변수로 설정합니다. 

Class가 양성(Positive)인 비율을 아래와 같이 변화를 주어 df_train을 Random Under Sampling방법으로 샘플하고 성능의 차이를 살펴 봅니다.

샘플링 데이터로 학습하고, df_test로 성능을 측정합니다.

성능 지표는 f1-score 이고, 학습 모델은 로지스틱 회귀(Logistic Regression)입니다.


negative_ratio = c(0.2, 0.25, 0.3, 0.4, 0.5)

```{r}
# 초기화
f1_train_ros <- c()
f1_test_ros <- c()
acc_train <- c()
acc_test <- c()

# 오버샘플링하지 않았을 경우의 성능 기록
result <- eval_model(logistic_reg, df_train, df_test, trace=FALSE)
acc_train <- c(acc_train, result[1])
f1_train_ros <- c(f1_train_ros, result[2])
acc_test <- c(acc_test, result[3])
f1_test_ros <- c(f1_test_ros, result[4])

# 제시한 오버샘플링 비율에 따른 성능 측정
negative_ratio <- c(0.2, 0.25, 0.3, 0.4, 0.5)

for (i in negative_ratio) {
  df_train_rus <- ovun.sample(target ~ ., data = df_train, method = "under", N = spam_cnt + spam_cnt * (1 / i))$data
  result <- eval_model(logistic_reg, df_train_rus, df_test, trace=FALSE)
  acc_train <- c(acc_train, result[1])
  f1_train_ros <- c(f1_train_ros, result[2])
  acc_test <- c(acc_test, result[3])
  f1_test_ros <- c(f1_test_ros, result[4])
}

negative_ratio <- c(sum(df_train$target == 'spam') / nrow(df_train), negative_ratio)

# 결과 시각화
results <- data.frame(
  Ratio = c(negative_ratio),
  F1_Train = f1_train_ros,
  F1_Test = f1_test_ros,
  Accuracy_Train = acc_train,
  Accuracy_Test = acc_test
)
```


```{r}
ggplot(results, aes(x = Ratio)) +
  geom_line(aes(y = F1_Train, color = 'F1 Train')) +
  geom_line(aes(y = F1_Test, color = 'F1 Test')) +
  geom_line(aes(y = Accuracy_Train, color = 'Accuracy Train')) +
  geom_line(aes(y = Accuracy_Test, color = 'Accuracy Test')) +
  labs(title = "Model Performance with Different Undersampling Ratios",
       x = "Negative Class Ratio",
       y = "Performance Metric") +
  theme_minimal() +
  scale_color_manual(name = "Metric", values = c("F1 Train" = "blue", "F1 Test" = "green", "Accuracy Train" = "red", "Accuracy Test" = "purple"))
```
### Tomek's Link 알고리즘

#### Tomek's Link

서로 다른 클래스에 속하는 두 점의 거리가 두 점에서의 가장 가까운 경우를 Tomek's Link라고 합니다.

Tomek's Link는 결정 경계면과 가깝게 위치하여 클래스 분류에 혼동을 일으킬 가능성이 높습니다.

Tomek's Link 중에서 둘 중에 하나의 클래스가 언더 샘플림 대상 클래스면 데이터셋에서 제외 시킵니다.

### 언더 샘플링의 장단점

#### 장점

- 데이터셋의 크기를 줄이기 때문에 모델 학습이 더 빠르게 진행될 수 있습니다.


- 잡음 감소: 다수 클래스의 샘플을 제거함으로써 데이터셋의 잡음감소 효과를 얻을 수 있습니다.
    
#### 단점

- 정보 손실: 다수 클래스의 샘플을 제거하면 데이터의 다양성이 감소할 수 있습니다. 
 

- 소수 클래스의 대표성 손실: 중요한 소수 클래스의 정보가 대조군이 되는 다수 클래스의 표본이 사라짐에 따라 정보가 손실이 될 수 있습니다.
    
    
    




